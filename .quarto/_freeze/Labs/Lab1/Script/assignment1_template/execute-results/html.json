{
  "hash": "19f287e8e7efd165b26b362db6cc3178",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Assignment 1: Census Data Quality for Policy Decisions\"\nsubtitle: \"Evaluating Data Reliability for Algorithmic Decision-Making\"\nauthor: \"Chloe Robinson\"\ndate: today\nformat: \n  html:\n    code-fold: false\n    toc: true\n    toc-location: left\n    theme: cosmo\nexecute:\n  warning: false\n  message: false\n---\n\n# Assignment Overview\n\n## Scenario\n\nYou are a data analyst for the **New York Department of Human Services**. The department is considering implementing an algorithmic system to identify communities that should receive priority for social service funding and outreach programs. Your supervisor has asked you to evaluate the quality and reliability of available census data to inform this decision.\n\nDrawing on our Week 2 discussion of algorithmic bias, you need to assess not just what the data shows, but how reliable it is and what communities might be affected by data quality issues.\n\n## Learning Objectives\n\n- Apply dplyr functions to real census data for policy analysis\n- Evaluate data quality using margins of error \n- Connect technical analysis to algorithmic decision-making\n- Identify potential equity implications of data reliability issues\n- Create professional documentation for policy stakeholders\n\n## Submission Instructions\n\n**Submit by posting your updated portfolio link on Canvas.** Your assignment should be accessible at `your-portfolio-url/assignments/assignment_1/`\n\nMake sure to update your `_quarto.yml` navigation to include this assignment under an \"Assignments\" menu.\n\n# Part 1: Portfolio Integration\n\nCreate this assignment in your portfolio repository under an `assignments/assignment_1/` folder structure. Update your navigation menu to include:\n\n```\n- text: Assignments\n  menu:\n    - href: assignments/assignment_1/your_file_name.qmd\n      text: \"Assignment 1: Census Data Exploration\"\n```\nIf there is a special character like comma, you need use double quote mark so that the quarto can identify this as text\n\n# Setup\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidycensus)\nlibrary(tidyverse)\nlibrary(knitr)\n\nmy_state <- \"New York\"\n```\n:::\n\n\n**State Selection:** I chose New York for this analysis because it’s where I hope to live and work one day, and it also has a wide mix of communities that make it interesting to study.\n\n# Part 2: County-Level Resource Assessment\n\n## 2.1 Data Retrieval\n\n**Your Task:** Use `get_acs()` to retrieve county-level data for your chosen state.\n\n**Requirements:**\n- Geography: county level\n- Variables: median household income (B19013_001) and total population (B01003_001)  \n- Year: 2022\n- Survey: acs5\n- Output format: wide\n\n**Hint:** Remember to give your variables descriptive names using the `variables = c(name = \"code\")` syntax.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncounty_data <- get_acs(\n  geography = \"county\",\n  variables = c(\n    total_pop = \"B01003_001\", \n    median_income = \"B19013_001\"\n  ),\n  state = my_state,\n  year = 2022,\n  survey = \"acs5\",\n  output = \"wide\"\n)\n\ncounty_data_clean <- county_data %>%\n  mutate(\n    county_name = str_remove(NAME, paste0(\", \", my_state)),\n    county_name = str_remove(county_name, \" County\")\n  )\n\nhead(county_data_clean)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 7\n  GEOID NAME     total_popE total_popM median_incomeE median_incomeM county_name\n  <chr> <chr>         <dbl>      <dbl>          <dbl>          <dbl> <chr>      \n1 36001 Albany …     315041         NA          78829           2049 Albany     \n2 36003 Allegan…      47222         NA          58725           1965 Allegany   \n3 36005 Bronx C…    1443229         NA          47036            890 Bronx      \n4 36007 Broome …     198365         NA          58317           1761 Broome     \n5 36009 Cattara…      77000         NA          56889           1778 Cattaraugus\n6 36011 Cayuga …      76171         NA          63227           2736 Cayuga     \n```\n\n\n:::\n:::\n\n\n## 2.2 Data Quality Assessment\n\n**Your Task:** Calculate margin of error percentages and create reliability categories.\n\n**Requirements:**\n- Calculate MOE percentage: (margin of error / estimate) * 100\n- Create reliability categories:\n  - High Confidence: MOE < 5%\n  - Moderate Confidence: MOE 5-10%  \n  - Low Confidence: MOE > 10%\n- Create a flag for unreliable estimates (MOE > 10%)\n\n**Hint:** Use `mutate()` with `case_when()` for the categories.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# MOE percentage and reliability categories using mutate()\ncounty_reliability <- county_data_clean %>%\n  mutate(\n    moe_percentage = round(100 * median_incomeM / median_incomeE, 2),\n    reliability = case_when(\n      moe_percentage < 5 ~ \"High Confidence\",\n      moe_percentage <= 10 ~ \"Moderate Confidence\",\n      moe_percentage > 10 ~ \"Low Confidence\",\n      TRUE ~ NA_character_\n    ),\n    unreliable = moe_percentage > 10   # <- required flag\n  )\n\n# Summary showing count of counties in each reliability category\nreliability_summary <- county_reliability %>%\n  group_by(reliability) %>%\n  summarize(\n    counties = n(),\n    avg_income = round(mean(median_incomeE, na.rm = TRUE), 0)\n  ) %>%\n  mutate(percent = round(counties / sum(counties) * 100, 1))\n\nreliability_summary\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 4\n  reliability         counties avg_income percent\n  <chr>                  <int>      <dbl>   <dbl>\n1 High Confidence           56      74300    90.3\n2 Low Confidence             1      66891     1.6\n3 Moderate Confidence        5      65545     8.1\n```\n\n\n:::\n:::\n\n\n## 2.3 High Uncertainty Counties\n\n**Your Task:** Identify the 5 counties with the highest MOE percentages.\n\n**Requirements:**\n- Sort by MOE percentage (highest first)\n- Select the top 5 counties\n- Display: county name, median income, margin of error, MOE percentage, reliability category\n- Format as a professional table using `kable()`\n\n**Hint:** Use `arrange()`, `slice()`, and `select()` functions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhigh_uncertainty <- county_reliability %>%\n  arrange(desc(moe_percentage)) %>%\n  slice_head(n = 5) %>%\n  select(county_name, total_popE, median_incomeE, median_incomeM, moe_percentage, reliability)\n\nkable(\n  high_uncertainty,\n  col.names = c(\"County\",\"Total Population\",\"Median Income (E)\",\"Median Income MOE\",\"MOE %\",\"Reliability\"),\n  caption = \"Counties with Highest Income Data Uncertainty\",\n  format.args = list(big.mark = \",\")\n)\n```\n\n::: {.cell-output-display}\n\n\nTable: Counties with Highest Income Data Uncertainty\n\n|County   | Total Population| Median Income (E)| Median Income MOE| MOE %|Reliability         |\n|:--------|----------------:|-----------------:|-----------------:|-----:|:-------------------|\n|Hamilton |            5,090|            66,891|             7,622| 11.39|Low Confidence      |\n|Schuyler |           17,855|            61,316|             5,818|  9.49|Moderate Confidence |\n|Greene   |           48,067|            70,294|             4,341|  6.18|Moderate Confidence |\n|Yates    |           24,713|            63,974|             3,733|  5.84|Moderate Confidence |\n|Essex    |           37,314|            68,090|             3,590|  5.27|Moderate Confidence |\n\n\n:::\n:::\n\n\n\n**Data Quality Commentary:**\n\nThis shows that counties with small populations are poorly served by algorithms that rely on this income data. Smaller populations mean smaller samples in the American Community Survey (ACS), which increases margins of error and makes estimates less certain, the true value could be higher or lower than reported. For example, Hamilton County has only about 5,000 people, which results in a high MOE of 11.39%.\n\n# Part 3: Neighborhood-Level Analysis\n\n## 3.1 Focus Area Selection\n\n**Your Task:** Select 2-3 counties from your reliability analysis for detailed tract-level study.\n\n**Strategy:** Choose counties that represent different reliability levels (e.g., 1 high confidence, 1 moderate, 1 low confidence) to compare how data quality varies.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nselected_counties <- county_reliability %>%\n  filter(county_name %in% c(\"Seneca\", \"New York\")) %>%\n  select(county_name, median_incomeE, moe_percentage, reliability)\n\nprint(selected_counties)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 4\n  county_name median_incomeE moe_percentage reliability        \n  <chr>                <dbl>          <dbl> <chr>              \n1 New York             99880           1.78 High Confidence    \n2 Seneca               64050           5.24 Moderate Confidence\n```\n\n\n:::\n:::\n\n\n**Comment on the output:** For this analysis I selected Seneca County and New York County. I chose these because they have different reliability levels, Seneca County falls in the Moderate Confidence category, and New York County falls in the High Confidence category. The contrast shows that because NY County has a higher population, the MOE is lower, and Seneca County has a much smaller population, leading to a higher MOE.\n\n## 3.2 Tract-Level Demographics\n\n**Your Task:** Get demographic data for census tracts in your selected counties.\n\n**Requirements:**\n- Geography: tract level\n- Variables: white alone (B03002_003), Black/African American (B03002_004), Hispanic/Latino (B03002_012), total population (B03002_001)\n- Use the same state and year as before\n- Output format: wide\n- **Challenge:** You'll need county codes, not names. Look at the GEOID patterns in your county data for hints.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntract_data <- get_acs(\n  geography = \"tract\",\n  variables = c(\n    white = \"B03002_003\",\n    black = \"B03002_004\",\n    hispanic = \"B03002_012\",\n    total_pop = \"B03002_001\"\n  ),\n  state = my_state,\n  county = c(\"061\", \"099\"),\n  year = 2022,\n  survey = \"acs5\",\n  output = \"wide\"\n)\n\ntract_data <- tract_data %>%\n  mutate(\n    pct_white    = 100 * whiteE    / total_popE,\n    pct_black    = 100 * blackE    / total_popE,\n    pct_hispanic = 100 * hispanicE / total_popE\n  )\n\ntract_data <- tract_data %>%\n  separate(NAME, into = c(\"tract_name\", \"county_name\", \"state_name\"), sep = \"; \")\n```\n:::\n\n\n## 3.3 Demographic Analysis\n\n**Your Task:** Analyze the demographic patterns in your selected areas.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhigh_hispanic <- tract_data %>%\n  arrange(desc(pct_hispanic)) %>%\n  slice(1) %>%\n  select(GEOID, tract_name, county_name, pct_hispanic)\n\ncounty_summary <- tract_data %>%\n  group_by(county_name) %>%\n  summarize(\n    n_tracts     = n(),\n    avg_white    = mean(pct_white, na.rm = TRUE),\n    avg_black    = mean(pct_black, na.rm = TRUE),\n    avg_hispanic = mean(pct_hispanic, na.rm = TRUE)\n  )\n\ncounty_summary %>%\n  kable(\n    digits = 1,\n    col.names = c(\"County\", \"Number of Tracts\", \n                  \"Avg % White\", \"Avg % Black\", \"Avg % Hispanic\"),\n    caption = \"Average Demographics by County\"\n  )\n```\n\n::: {.cell-output-display}\n\n\nTable: Average Demographics by County\n\n|County          | Number of Tracts| Avg % White| Avg % Black| Avg % Hispanic|\n|:---------------|----------------:|-----------:|-----------:|--------------:|\n|New York County |              310|        47.3|        12.7|           22.9|\n|Seneca County   |               11|        84.5|         7.2|            4.3|\n\n\n:::\n:::\n\n\n# Part 4: Comprehensive Data Quality Evaluation\n\n## 4.1 MOE Analysis for Demographic Variables\n\n**Your Task:** Examine margins of error for demographic variables to see if some communities have less reliable data.\n\n**Requirements:**\n- Calculate MOE percentages for each demographic variable\n- Flag tracts where any demographic variable has MOE > 15%\n- Create summary statistics\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntract_data <- tract_data %>%\n  mutate(\n    moe_white    = 100 * (whiteM    / whiteE),\n    moe_black    = 100 * (blackM    / blackE),\n    moe_hispanic = 100 * (hispanicM / hispanicE),\n    high_moe_flag = ifelse(\n      moe_white > 15 | moe_black > 15 | moe_hispanic > 15,\n      \"High MOE\", \"Other\"\n    ),\n    high_moe_flag_30 = ifelse(\n      moe_white > 30 | moe_black > 30 | moe_hispanic > 30,\n      \"High MOE\", \"Lower MOE\"\n    )\n  )  \n```\n:::\n\n\n## 4.2 Pattern Analysis\n\n**Your Task:** Investigate whether data quality problems are randomly distributed or concentrated in certain types of communities.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMOE_analysis_15 <- tract_data %>%\n  group_by(high_moe_flag) %>%\n  summarize(\n    n_tracts        = n(),\n    avg_pop         = mean(total_popE, na.rm = TRUE),\n    avg_pct_white   = mean(pct_white, na.rm = TRUE),\n    avg_pct_black   = mean(pct_black, na.rm = TRUE),\n    avg_pct_hispanic= mean(pct_hispanic, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\nMOE_analysis_30 <- tract_data %>%\n  group_by(high_moe_flag_30) %>%\n  summarize(\n    n_tracts        = n(),\n    avg_pop         = mean(total_popE, na.rm = TRUE),\n    avg_pct_white   = mean(pct_white, na.rm = TRUE),\n    avg_pct_black   = mean(pct_black, na.rm = TRUE),\n    avg_pct_hispanic= mean(pct_hispanic, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\nkable(\n  MOE_analysis_15,\n  digits = 1,\n  col.names = c(\"MOE Group (15%)\", \"Number of Tracts\", \"Avg Population\",\n                \"Avg % White\", \"Avg % Black\", \"Avg % Hispanic\"),\n  caption = \"Tract Summary 15% MOE Cutoff\"\n)\n```\n\n::: {.cell-output-display}\n\n\nTable: Tract Summary 15% MOE Cutoff\n\n|MOE Group (15%) | Number of Tracts| Avg Population| Avg % White| Avg % Black| Avg % Hispanic|\n|:---------------|----------------:|--------------:|-----------:|-----------:|--------------:|\n|High MOE        |              321|         5232.1|        48.6|        12.5|           22.3|\n\n\n:::\n\n```{.r .cell-code}\nkable(MOE_analysis_30,\n      digits = 1,\n      col.names = c(\"MOE Group (30%)\", \"Number of Tracts\", \"Avg Population\",\n                    \"Avg % White\", \"Avg % Black\", \"Avg % Hispanic\"),\n      caption = \"Tract Summary 30% MOE Cutoff\")\n```\n\n::: {.cell-output-display}\n\n\nTable: Tract Summary 30% MOE Cutoff\n\n|MOE Group (30%) | Number of Tracts| Avg Population| Avg % White| Avg % Black| Avg % Hispanic|\n|:---------------|----------------:|--------------:|-----------:|-----------:|--------------:|\n|High MOE        |              313|         5217.3|        49.2|        12.3|           21.9|\n|Lower MOE       |                8|         5812.1|        26.5|        22.2|           36.9|\n\n\n:::\n\n```{.r .cell-code}\n#Further investigation - Population Distributions (not asked in assignment)\nprint(\n  tract_data %>%\n    group_by(high_moe_flag_30) %>%\n    summarize(\n      n_tracts   = n(),\n      avg_pop    = mean(total_popE, na.rm = TRUE),\n      median_pop = median(total_popE, na.rm = TRUE)\n    )\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 4\n  high_moe_flag_30 n_tracts avg_pop median_pop\n  <chr>               <int>   <dbl>      <dbl>\n1 High MOE              313   5217.       4879\n2 Lower MOE               8   5812.       6194\n```\n\n\n:::\n:::\n\n\n**Pattern Analysis:** Initially a cut-off of 15% was used, and all of the tracts fell into the 'High MOE' category, suggesting uncertainty. When a cut-off of 30% was used, a small number of tracts fell into the 'Lower MOE' category, meaning this subset is more reliable. Interestingly, these Lower MOE tracts are more diverse than the higher MOE tracts. This pattern shows that more diverse areas often produce more reliable results, mainly because they also tend to have larger populations. Diversity itself is not the cause of lower MOEs, but it appears indirectly since diverse tracts are often larger and therefore more accurately captured in the ACS.\n\n# Part 5: Policy Recommendations\n\n## 5.1 Analysis Integration and Professional Summary\n\n**Your Task:** Write an executive summary that integrates findings from all four analyses.\n\nDuring my analysis, I found that there is a systematic pattern showing that data quality varies a lot between counties and census tracts. When analyzing the county data, I saw that the counties with the highest populations had the highest quality of data, as can be seen with New York County, with a margin of error of only 1.78% compared to Seneca County with a much higher margin of error of 5.24%.  The same pattern could be seen at the census tract level, where the tracts with a smaller population or less diversity had less reliable estimates compared to those with a larger, more diverse population. \n\nThe communities that face the greatest risk of being misclassified by algorithms are smaller, rural, and less diverse counties. Income estimates for these areas have higher margins of error, meaning they are less precise and the true income could be much higher or lower than the estimate. This could cause areas such as Seneca County to be misclassified as an area of need, leading to too few resources being allocated to the county, for example.\n\nThe root cause of these reliability issues is that the American Community Survey (ACS) collects fewer samples in small or rural communities. Smaller samples lead to higher margins of error, while large urban areas benefit from more precise estimates. This means that the reliability of the survey is not evenly distributed across different community types.    \n\nThe Department should implement case-by-case reviews of the communities that show high margins of error. These areas need closer analysis and should not be grouped together under the same assumptions used for larger, more reliable communities.\n\n## 6.3 Specific Recommendations\n\n**Your Task:** Create a decision framework for algorithm implementation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrecommendations_data <- county_reliability %>%\n  select(county_name, median_incomeE, moe_percentage, reliability) %>%\n  mutate(\n    recommendation = case_when(\n      reliability == \"High Confidence\"    ~ \"Safe for algorithmic decisions\",\n      reliability == \"Moderate Confidence\" ~ \"Use with caution - monitor outcomes\",\n      reliability == \"Low Confidence\"     ~ \"Requires manual review or additional data\",\n      TRUE ~ \"Unclassified\"\n    )\n  )\n\nkable(\n  recommendations_data,\n  digits = 1,\n  col.names = c(\"County\",\"Median Income\",\"MOE %\",\"Reliability\",\"Recommendation\"),\n  caption = \"Algorithmic Decision Framework by County\",\n  format.args = list(big.mark = \",\")\n)\n```\n\n::: {.cell-output-display}\n\n\nTable: Algorithmic Decision Framework by County\n\n|County       | Median Income| MOE %|Reliability         |Recommendation                            |\n|:------------|-------------:|-----:|:-------------------|:-----------------------------------------|\n|Albany       |        78,829|   2.6|High Confidence     |Safe for algorithmic decisions            |\n|Allegany     |        58,725|   3.4|High Confidence     |Safe for algorithmic decisions            |\n|Bronx        |        47,036|   1.9|High Confidence     |Safe for algorithmic decisions            |\n|Broome       |        58,317|   3.0|High Confidence     |Safe for algorithmic decisions            |\n|Cattaraugus  |        56,889|   3.1|High Confidence     |Safe for algorithmic decisions            |\n|Cayuga       |        63,227|   4.3|High Confidence     |Safe for algorithmic decisions            |\n|Chautauqua   |        54,625|   3.2|High Confidence     |Safe for algorithmic decisions            |\n|Chemung      |        61,358|   4.0|High Confidence     |Safe for algorithmic decisions            |\n|Chenango     |        61,741|   4.1|High Confidence     |Safe for algorithmic decisions            |\n|Clinton      |        67,097|   4.2|High Confidence     |Safe for algorithmic decisions            |\n|Columbia     |        81,741|   3.4|High Confidence     |Safe for algorithmic decisions            |\n|Cortland     |        65,029|   4.4|High Confidence     |Safe for algorithmic decisions            |\n|Delaware     |        58,338|   3.7|High Confidence     |Safe for algorithmic decisions            |\n|Dutchess     |        94,578|   2.7|High Confidence     |Safe for algorithmic decisions            |\n|Erie         |        68,014|   1.2|High Confidence     |Safe for algorithmic decisions            |\n|Essex        |        68,090|   5.3|Moderate Confidence |Use with caution - monitor outcomes       |\n|Franklin     |        60,270|   4.8|High Confidence     |Safe for algorithmic decisions            |\n|Fulton       |        60,557|   4.4|High Confidence     |Safe for algorithmic decisions            |\n|Genesee      |        68,178|   4.6|High Confidence     |Safe for algorithmic decisions            |\n|Greene       |        70,294|   6.2|Moderate Confidence |Use with caution - monitor outcomes       |\n|Hamilton     |        66,891|  11.4|Low Confidence      |Requires manual review or additional data |\n|Herkimer     |        68,104|   4.8|High Confidence     |Safe for algorithmic decisions            |\n|Jefferson    |        62,782|   3.6|High Confidence     |Safe for algorithmic decisions            |\n|Kings        |        74,692|   1.3|High Confidence     |Safe for algorithmic decisions            |\n|Lewis        |        64,401|   4.2|High Confidence     |Safe for algorithmic decisions            |\n|Livingston   |        70,443|   4.0|High Confidence     |Safe for algorithmic decisions            |\n|Madison      |        68,869|   4.0|High Confidence     |Safe for algorithmic decisions            |\n|Monroe       |        71,450|   1.4|High Confidence     |Safe for algorithmic decisions            |\n|Montgomery   |        58,033|   3.6|High Confidence     |Safe for algorithmic decisions            |\n|Nassau       |       137,709|   1.4|High Confidence     |Safe for algorithmic decisions            |\n|New York     |        99,880|   1.8|High Confidence     |Safe for algorithmic decisions            |\n|Niagara      |        65,882|   2.7|High Confidence     |Safe for algorithmic decisions            |\n|Oneida       |        66,402|   3.3|High Confidence     |Safe for algorithmic decisions            |\n|Onondaga     |        71,479|   1.6|High Confidence     |Safe for algorithmic decisions            |\n|Ontario      |        76,603|   2.9|High Confidence     |Safe for algorithmic decisions            |\n|Orange       |        91,806|   1.9|High Confidence     |Safe for algorithmic decisions            |\n|Orleans      |        61,069|   4.9|High Confidence     |Safe for algorithmic decisions            |\n|Oswego       |        65,054|   3.3|High Confidence     |Safe for algorithmic decisions            |\n|Otsego       |        65,778|   4.5|High Confidence     |Safe for algorithmic decisions            |\n|Putnam       |       120,970|   4.0|High Confidence     |Safe for algorithmic decisions            |\n|Queens       |        82,431|   1.1|High Confidence     |Safe for algorithmic decisions            |\n|Rensselaer   |        83,734|   2.3|High Confidence     |Safe for algorithmic decisions            |\n|Richmond     |        96,185|   2.6|High Confidence     |Safe for algorithmic decisions            |\n|Rockland     |       106,173|   2.9|High Confidence     |Safe for algorithmic decisions            |\n|St. Lawrence |        58,339|   3.5|High Confidence     |Safe for algorithmic decisions            |\n|Saratoga     |        97,038|   2.3|High Confidence     |Safe for algorithmic decisions            |\n|Schenectady  |        75,056|   3.0|High Confidence     |Safe for algorithmic decisions            |\n|Schoharie    |        71,479|   4.0|High Confidence     |Safe for algorithmic decisions            |\n|Schuyler     |        61,316|   9.5|Moderate Confidence |Use with caution - monitor outcomes       |\n|Seneca       |        64,050|   5.2|Moderate Confidence |Use with caution - monitor outcomes       |\n|Steuben      |        62,506|   2.9|High Confidence     |Safe for algorithmic decisions            |\n|Suffolk      |       122,498|   1.2|High Confidence     |Safe for algorithmic decisions            |\n|Sullivan     |        67,841|   4.3|High Confidence     |Safe for algorithmic decisions            |\n|Tioga        |        70,427|   4.0|High Confidence     |Safe for algorithmic decisions            |\n|Tompkins     |        69,995|   4.0|High Confidence     |Safe for algorithmic decisions            |\n|Ulster       |        77,197|   4.5|High Confidence     |Safe for algorithmic decisions            |\n|Warren       |        74,531|   4.7|High Confidence     |Safe for algorithmic decisions            |\n|Washington   |        68,703|   3.4|High Confidence     |Safe for algorithmic decisions            |\n|Wayne        |        71,007|   3.1|High Confidence     |Safe for algorithmic decisions            |\n|Westchester  |       114,651|   1.6|High Confidence     |Safe for algorithmic decisions            |\n|Wyoming      |        65,066|   3.4|High Confidence     |Safe for algorithmic decisions            |\n|Yates        |        63,974|   5.8|Moderate Confidence |Use with caution - monitor outcomes       |\n\n\n:::\n:::\n\n\n**Key Recommendations:**\n\n**Your Task:** Use your analysis results to provide specific guidance to the department.\n\n1. **Counties suitable for immediate algorithmic implementation:** All counties in New York State, except 6 are high confidence. The counties with the highest confidence are Queens, Erie, Suffolk, Kings, Monroe, Nassau, Westchester, Onondaga, New York, Bronx, and Orange, which all have a margin of error of less than 2%. These counties are suitable for immediate algorithmic implementation as they are very high confidence.\n\n2. **Counties requiring additional oversight:** There are only 5 counties that are moderate confidence, a margin of error between 5% and 10%. These counties are Essex, Yates, Greene, Schuyler, and Seneca. The income estimates in these counties should be monitored closely and reviewed manually to ensure that resources can be allocated fairly.\n\n3. **Counties needing alternative approaches:** Hamilton County (11% MOE) is the only county in the low confidence category. This means that its income estimate is very unreliable due to sampling uncertainty and should not be used for algorithmic decisions without additional checks. Community-level surveys should be conducted and manually reviewed in addition to the ACS data to guide policy decision making. \n\n## Further Investigation\nI would like to spatially represent the findings across the whole state at county level, to see if the pattern holds that the rural areas have higher margins of error than urban areas. I would also like to see if there is any correlation between age and education and income margin of errors, similar to how I analyzed racial demographics in this assignment. \n\n# Technical Notes\n\n**Data Sources:** \n- U.S. Census Bureau, American Community Survey 2018-2022 5-Year Estimates\n- Retrieved via tidycensus R package on 09/27/2025\n\n**Reproducibility:** \n- All analysis conducted in R version 4.4.1\n- Census API key required for replication\n- Complete code and documentation available at: https://musa-5080-fall-2025.github.io/portfolio-setup-chloelr/\n\n**Methodology Notes:**\nIn this analysis, the 2022 ACS 5-Year estimates wer used from the Census Bureau, which I brought into R using the tidycensus package. The state I chose for my analysis was New York, and analyzed income margins of error at county level for New York County and Seneca County. Then, using these counties, I analyzed demographics margins of error at census tract level. \n\n**Limitations:**\nThe first issue I encountered was when I tried to use Hamilton as the low confidence county to analyze. The ACS sample size there was too small, which led to high uncertainty and missing values (NAs) at the tract level. I then chose a different county to analyze and chose Seneca County which was in the moderate confidence category. Another issue I encountered was when I used a high margin of error cut-off of 15% for census tracts within New York and Seneca County. At this threshold, all 321 tracts were classified as ‘High MOE’. I then raised the cut-off to 30% and saw that 8 tracts shifted to ‘Lower MOE’. \n\n---\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}