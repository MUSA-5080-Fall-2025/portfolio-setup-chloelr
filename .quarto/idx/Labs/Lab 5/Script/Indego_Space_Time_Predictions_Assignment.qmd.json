{"title":"Space-Time Prediction of Bike Share Demand: Philadelphia Indego","markdown":{"yaml":{"title":"Space-Time Prediction of Bike Share Demand: Philadelphia Indego","author":"Chloe Robinson","date":"`r Sys.Date()`","code-fold":false,"code-tools":false,"format":{"html":{"toc":true,"toc-depth":3,"toc-location":"left","theme":"cosmo","embed-resources":true}},"editor":"visual","execute":{"warning":false,"message":false,"freeze":false,"cache":false}},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n```{r}\n#| echo: false\nknitr::opts_chunk$set(\n  echo = TRUE,\n  warning = FALSE,\n  message = FALSE,\n  cache = TRUE\n)\n```\n\n\n## The Rebalancing Challenge in Philadelphia\n\nPhiladelphia's Indego bike share system faces the same operational challenge as every bike share system: **rebalancing bikes to meet anticipated demand**.\n\nImagine you're an Indego operations manager at 6:00 AM on a Monday morning. You have: - 200 stations across Philadelphia - Limited trucks and staff for moving bikes - 2-3 hours before morning rush hour demand peaks - **The question:** Which stations will run out of bikes by 8:30 AM?\n\nThis lab will teach you to build predictive models that forecast bike share demand across **space** (different stations) and **time** (different hours) to help solve this operational problem.\n\n------------------------------------------------------------------------\n\n```{r}\n#| echo: false\n# Core tidyverse\nlibrary(tidyverse)\nlibrary(lubridate)\n\n# Spatial data\nlibrary(sf)\nlibrary(tigris)\n\n# Census data\nlibrary(tidycensus)\n\n# Weather data\nlibrary(riem)  # For Philadelphia weather from ASOS stations\n\n\n# Visualization\nlibrary(viridis)\nlibrary(gridExtra)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(zoo)\n\n# here!\nlibrary(here)\n# Get rid of scientific notation. We gotta look good!\noptions(scipen = 999)\n```\n\n```{r}\n#| echo: false\nplotTheme <- theme(\n  plot.title = element_text(size = 14, face = \"bold\"),\n  plot.subtitle = element_text(size = 10),\n  plot.caption = element_text(size = 8),\n  axis.text.x = element_text(size = 10, angle = 45, hjust = 1),\n  axis.text.y = element_text(size = 10),\n  axis.title = element_text(size = 11, face = \"bold\"),\n  panel.background = element_blank(),\n  panel.grid.major = element_line(colour = \"#D0D0D0\", size = 0.2),\n  panel.grid.minor = element_blank(),\n  axis.ticks = element_blank(),\n  legend.position = \"right\"\n)\n\nmapTheme <- theme(\n  plot.title = element_text(size = 14, face = \"bold\"),\n  plot.subtitle = element_text(size = 10),\n  plot.caption = element_text(size = 8),\n  axis.line = element_blank(),\n  axis.text = element_blank(),\n  axis.ticks = element_blank(),\n  axis.title = element_blank(),\n  panel.background = element_blank(),\n  panel.border = element_blank(),\n  panel.grid.major = element_line(colour = 'transparent'),\n  panel.grid.minor = element_blank(),\n  legend.position = \"right\",\n  plot.margin = margin(1, 1, 1, 1, 'cm'),\n  legend.key.height = unit(1, \"cm\"),\n  legend.key.width = unit(0.2, \"cm\")\n)\n\npalette5 <- c(\"#eff3ff\", \"#bdd7e7\", \"#6baed6\", \"#3182bd\", \"#08519c\")\n```\n\n# Data Import & Preparation\n\n## Load Indego Trip Data (Q1 2025)\n\n```{r}\n#| echo: false\n#| message: false \n#| output: false\n\n# Read Q1 2025 data\nindego_q1 <- read_csv(\n  here(\"C:/Users/chloe.robinson/Desktop/PENN/FALL 2025/Public Policy Analytics/Week 1/portfolio-setup-chloelr/Labs/Lab 5/Data/indego-trips-2025-q1.csv\")\n)\n\n# Quick look at the data\nglimpse(indego_q1)\n```\n\n```{r}\n#| echo: false\n#| results: hide\n#| message: false\n#| warning: false\n\n# How many trips?\ncat(\"Total trips in Q1 2025:\", nrow(indego_q1), \"\\n\")\n\n# Date range\ncat(\"Date range:\",\n    min(mdy_hm(indego_q1$start_time)), \"to\",\n    max(mdy_hm(indego_q1$start_time)), \"\\n\")\n\n# How many unique stations?\ncat(\"Unique start stations:\", length(unique(indego_q1$start_station)), \"\\n\")\n\n# Trip types\ntable(indego_q1$trip_route_category)\n\n# Passholder types\ntable(indego_q1$passholder_type)\n\n# Bike types\ntable(indego_q1$bike_type)\n```\n\n```{r summary_table_q1}\n#| echo: false\n#| message: false\n#| warning: false\n\nsummary_table_q1 <- tibble(\n  `Total Trips`           = nrow(indego_q1),\n  `Date Range Start`      = min(mdy_hm(indego_q1$start_time)),\n  `Date Range End`        = max(mdy_hm(indego_q1$start_time)),\n  `Unique Start Stations` = length(unique(indego_q1$start_station))\n)\n\nkable(summary_table_q1, caption = \"Summary of Indego Trip Data – Q1 2025\") |>\n  kable_styling(latex_options = \"hold_position\")\n```\n\n## Create Time Bins (Q1 2025)\n\n```{r}\nindego_q1 <- indego_q1 %>%\n  mutate(\n    # Parse datetime\n    start_datetime = mdy_hm(start_time),\n    end_datetime   = mdy_hm(end_time),\n\n    # Create hourly bins\n    interval60 = floor_date(start_datetime, unit = \"hour\"),\n\n    # Extract time features\n    week  = week(interval60),\n    month = month(interval60, label = TRUE),\n    dotw  = wday(interval60, label = TRUE),\n    hour  = hour(interval60),\n    date  = as.Date(interval60),\n\n    # Create useful indicators\n    weekend   = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n```\n\n```{r}\n#| echo: false\n\nindego_q1 %>%\n  select(start_datetime, interval60, week, dotw, hour, weekend) %>%\n  head(10) %>%\n  kable(caption = \"Preview of temporal features – Q1 2025\") %>%\n  kable_styling(latex_options = c(\"striped\", \"hold_position\"))\n```\n\n# Exploratory Analysis Q1 2025\n\n## Trips Over Time (Q1 2025)\n\n```{r}\n# Daily trip counts\ndaily_trips_q1 <- indego_q1 %>%\n  group_by(date) %>%\n  summarize(trips = n())\n\nggplot(daily_trips_q1, aes(x = date, y = trips)) +\n  geom_line(color = \"#3182bd\", linewidth = 1) +\n  geom_smooth(se = FALSE, color = \"red\", linetype = \"dashed\") +\n  labs(\n    title = \"Indego Daily Ridership – Q1 2025\",\n    subtitle = \"Winter ridership patterns in Philadelphia\",\n    x = \"Date\",\n    y = \"Daily Trips\",\n    caption = \"Source: Indego bike share\"\n  ) +\n  plotTheme\n```\n\n## Hourly Patterns (Q1 2025)\n\n```{r}\nhourly_patterns_q1 <- indego_q1 %>%\n  group_by(hour, weekend) %>%\n  summarize(avg_trips = n() / n_distinct(date)) %>%\n  mutate(day_type = ifelse(weekend == 1, \"Weekend\", \"Weekday\"))\n\nggplot(hourly_patterns_q1, aes(x = hour, y = avg_trips, color = day_type)) +\n  geom_line(linewidth = 1.2) +\n  scale_color_manual(values = c(\"Weekday\" = \"#08519c\", \"Weekend\" = \"#6baed6\")) +\n  labs(\n    title = \"Average Hourly Ridership Patterns – Q1 2025\",\n    subtitle = \"Weekday commute peaks vs. weekend leisure patterns\",\n    x = \"Hour of Day\",\n    y = \"Average Trips per Hour\",\n    color = \"Day Type\"\n  ) +\n  plotTheme\n```\n\n## Top Stations (Q1 2025)\n\n```{r}\ntop_stations_q1 <- indego_q1 %>%\n  count(start_station, start_lat, start_lon, name = \"trips\") %>%\n  arrange(desc(trips)) %>%\n  head(10)\n```\n\n```{r}\n#| echo: false\n\nkable(top_stations_q1,\n      caption = \"Top 10 Indego Stations by Trip Origins – Q1 2025\",\n      format.args = list(big.mark = \",\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n# Get Philadelphia Spatial Context (Q1 2025)\n\n## Load Philadelphia Census Data(Q1 2025)\n\n```{r load_census_q1}\n#| echo: false\n#| results: hide\n#| message: false\n#| warning: false\n\nphilly_census_q1 <- get_acs(\n  geography = \"tract\",\n  variables = c(\n    \"B01003_001\",\n    \"B19013_001\",\n    \"B08301_001\",\n    \"B08301_010\",\n    \"B02001_002\",\n    \"B25077_001\"\n  ),\n  state = \"PA\",\n  county = \"Philadelphia\",\n  year = 2022,\n  geometry = TRUE,\n  output = \"wide\"\n) %>%\n  rename(\n    Total_Pop = B01003_001E,\n    Med_Inc = B19013_001E,\n    Total_Commuters = B08301_001E,\n    Transit_Commuters = B08301_010E,\n    White_Pop = B02001_002E,\n    Med_Home_Value = B25077_001E\n  ) %>%\n  mutate(\n    Percent_Taking_Transit = (Transit_Commuters / Total_Commuters) * 100,\n    Percent_White = (White_Pop / Total_Pop) * 100\n  ) %>%\n  st_transform(crs = 4326)\n\nglimpse(philly_census_q1)\n```\n\n## Map Philadelphia Context (Q1 2025)\n\n```{r map_philly_q1}\nggplot() +\n  geom_sf(data = philly_census_q1, aes(fill = Med_Inc), color = NA) +\n  scale_fill_viridis(\n    option = \"viridis\",\n    name = \"Median\\nIncome\",\n    labels = scales::dollar\n  ) +\n  labs(\n    title = \"Philadelphia Median Household Income by Census Tract (Q1 2025)\",\n    subtitle = \"Context for bike share demand\"\n  ) +\n  geom_point(\n    data = indego_q1,\n    aes(x = start_lon, y = start_lat),\n    color = \"red\", size = 0.25, alpha = 0.6\n  ) +\n  mapTheme\n```\n\n## Join Census Data to Stations\n\n```{r join_census_to_stations_q1}\nstations_sf_q1 <- indego_q1 %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  st_as_sf(coords = c(\"start_lon\", \"start_lat\"), crs = 4326)\n\nstations_census_q1 <- st_join(stations_sf_q1, philly_census_q1, left = TRUE) %>%\n  st_drop_geometry()\n\nstations_for_map_q1 <- indego_q1 %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  left_join(\n    stations_census_q1 %>% select(start_station, Med_Inc),\n    by = \"start_station\"\n  ) %>%\n  mutate(has_census = !is.na(Med_Inc))\n\nindego_census_q1 <- indego_q1 %>%\n  left_join(\n    stations_census_q1 %>% \n      select(start_station, Med_Inc, Percent_Taking_Transit, Percent_White, Total_Pop),\n      by = \"start_station\"\n  )\n```\n\n```{r join_census_to_stations2_q1}\n#| echo: false\nstations_for_map_q1 <- indego_q1 %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  left_join(\n    stations_census_q1 %>% select(start_station, Med_Inc),\n    by = \"start_station\"\n  ) %>%\n  mutate(has_census = !is.na(Med_Inc))\n\nggplot() +\n  geom_sf(data = philly_census_q1, aes(fill = Med_Inc), color = \"white\", size = 0.1) +\n  scale_fill_viridis(\n    option = \"viridis\",\n    name = \"Median\\nIncome\",\n    labels = scales::dollar,\n    na.value = \"grey90\"\n  ) +\n  geom_point(\n    data = stations_for_map_q1 %>% filter(has_census),\n    aes(x = start_lon, y = start_lat),\n    color = \"grey30\", size = 1, alpha = 0.6\n  ) +\n  geom_point(\n    data = stations_for_map_q1 %>% filter(!has_census),\n    aes(x = start_lon, y = start_lat),\n    color = \"red\", size = 1, shape = 4, stroke = 1.5\n  ) +\n  labs(\n    title = \"Philadelphia Median Household Income (Q1 2025)\",\n    subtitle = \"RED = stations without census match\",\n    caption = \"Non-residential or outside-tract stations\"\n  ) +\n  mapTheme\n```\n\n```{r}\nvalid_stations_q1 <- stations_census_q1 %>%\n  filter(!is.na(Med_Inc)) %>%\n  pull(start_station)\n\nindego_census_q1 <- indego_q1 %>%\n  filter(start_station %in% valid_stations_q1) %>%\n  left_join(\n    stations_census_q1 %>% \n      select(start_station, Med_Inc, Percent_Taking_Transit, \n             Percent_White, Total_Pop),\n    by = \"start_station\"\n  )\n```\n\n# Dealing with missing data (Q1 2025)\n\n## Get Weather Data (Q1 2025)\n\n```{r get_weather_q1}\nweather_data_q1 <- riem_measures(\n  station    = \"PHL\",\n  date_start = \"2025-01-01\",\n  date_end   = \"2025-03-31\"\n)\n\nweather_processed_q1 <- weather_data_q1 %>%\n  mutate(\n    interval60    = floor_date(valid, unit = \"hour\"),\n    Temperature   = tmpf,\n    Precipitation = ifelse(is.na(p01i), 0, p01i),\n    Wind_Speed    = sknt\n  ) %>%\n  select(interval60, Temperature, Precipitation, Wind_Speed) %>%\n  distinct()\n\nweather_complete_q1 <- weather_processed_q1 %>%\n  complete(interval60 = seq(min(interval60), max(interval60), by = \"hour\")) %>%\n  fill(Temperature, Precipitation, Wind_Speed, .direction = \"down\")\n```\n\n## Visualize Weather Patterns (Q1 2025)\n\n```{r visualize_weather_q1}\nggplot(weather_complete_q1, aes(x = interval60, y = Temperature)) +\n  geom_line(color = \"#3182bd\", alpha = 0.7) +\n  geom_smooth(se = FALSE, color = \"red\") +\n  labs(\n    title = \"Philadelphia Temperature – Q1 2025\",\n    subtitle = \"Winter conditions\",\n    x = \"Date\",\n    y = \"Temperature (°F)\"\n  ) +\n  plotTheme\n```\n\n# Create Space-TIme Panel\n\n## Aggregate Trips to Station-Hour Level (Q1 2025)\n\n```{r aggregate_trips_q1}\ntrips_panel_q1 <- indego_census_q1 %>%\n  group_by(interval60, start_station, start_lat, start_lon,\n           Med_Inc, Percent_Taking_Transit, Percent_White, Total_Pop) %>%\n  summarize(Trip_Count = n()) %>%\n  ungroup()\n```\n\n## Create Complete Panel Structure (Q1 2025)\n\n```{r complete_panel_q1}\nn_stations_q1 <- length(unique(trips_panel_q1$start_station))\nn_hours_q1    <- length(unique(trips_panel_q1$interval60))\nexpected_rows_q1 <- n_stations_q1 * n_hours_q1\n\nstudy_panel_q1 <- expand.grid(\n  interval60   = unique(trips_panel_q1$interval60),\n  start_station = unique(trips_panel_q1$start_station)\n) %>%\n  left_join(trips_panel_q1, by = c(\"interval60\", \"start_station\")) %>%\n  mutate(Trip_Count = replace_na(Trip_Count, 0))\n\nstation_attributes_q1 <- trips_panel_q1 %>%\n  group_by(start_station) %>%\n  summarize(\n    start_lat = first(start_lat),\n    start_lon = first(start_lon),\n    Med_Inc   = first(Med_Inc),\n    Percent_Taking_Transit = first(Percent_Taking_Transit),\n    Percent_White = first(Percent_White),\n    Total_Pop = first(Total_Pop)\n  )\n\nstudy_panel_q1 <- study_panel_q1 %>%\n  left_join(station_attributes_q1, by = \"start_station\")\n```\n\n## Add Time Features (Q1 2025)\n\n```{r add_time_features_q1}\nstudy_panel_q1 <- study_panel_q1 %>%\n  mutate(\n    week     = week(interval60),\n    month    = month(interval60, label = TRUE),\n    dotw     = wday(interval60, label = TRUE),\n    hour     = hour(interval60),\n    date     = as.Date(interval60),\n    weekend  = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n```\n\n## Join Weather Data (Q1 2025)\n\n```{r join_weather_q1}\nstudy_panel_q1 <- study_panel_q1 %>%\n  left_join(weather_complete_q1, by = \"interval60\")\n```\n\n#Create Temporal Lag Variables (Q1 2025)\n\n```{r create_lags_q1}\nstudy_panel_q1 <- study_panel_q1 %>%\n  arrange(start_station, interval60)\n\nstudy_panel_q1 <- study_panel_q1 %>%\n  group_by(start_station) %>%\n  mutate(\n    lag1Hour   = lag(Trip_Count, 1),\n    lag2Hours  = lag(Trip_Count, 2),\n    lag3Hours  = lag(Trip_Count, 3),\n    lag12Hours = lag(Trip_Count, 12),\n    lag1day    = lag(Trip_Count, 24)\n  ) %>%\n  ungroup()\n\nstudy_panel_complete_q1 <- study_panel_q1 %>%\n  filter(!is.na(lag1day))\n\nstudy_panel_complete_q1 <- study_panel_complete_q1 %>%\n  mutate(\n    month = factor(month, levels = c(\"Jan\", \"Feb\", \"Mar\")),\n    dotw  = factor(dotw,  levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"))\n  )\n```\n\n```{r lag_correlations_q1}\nexample_station_q1 <- study_panel_complete_q1 %>%\n  filter(start_station == first(start_station)) %>%\n  head(168)\n\nggplot(example_station_q1, aes(x = interval60)) +\n  geom_line(aes(y = Trip_Count, color = \"Current\"), linewidth = 1) +\n  geom_line(aes(y = lag1Hour, color = \"1 Hour Ago\"), linewidth = 1, alpha = 0.7) +\n  geom_line(aes(y = lag1day, color = \"24 Hours Ago\"), linewidth = 1, alpha = 0.7) +\n  scale_color_manual(values = c(\n    \"Current\"     = \"#08519c\",\n    \"1 Hour Ago\"  = \"#3182bd\",\n    \"24 Hours Ago\"= \"#6baed6\"\n  )) +\n  labs(\n    title  = \"Temporal Lag Patterns at One Station – Q1 2025\",\n    x      = \"Date-Time\",\n    y      = \"Trip Count\",\n    color  = \"Time Period\"\n  ) +\n  plotTheme\n```\n\n## Temporal Train/Test Split (Q1 2025)\n\n```{r temporal_split_q1}\ntrain_weeks_q1 <- 1:9\ntest_weeks_q1  <- 10:13\n\nearly_stations_q1 <- study_panel_complete_q1 %>%\n  filter(week %in% train_weeks_q1, Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\nlate_stations_q1 <- study_panel_complete_q1 %>%\n  filter(week %in% test_weeks_q1, Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\ncommon_stations_q1 <- intersect(early_stations_q1, late_stations_q1)\n\nstudy_panel_q1_ts <- study_panel_complete_q1 %>%\n  filter(start_station %in% common_stations_q1)\n\ntrain_q1 <- study_panel_q1_ts %>%\n  filter(week %in% train_weeks_q1)\n\ntest_q1 <- study_panel_q1_ts %>%\n  filter(week %in% test_weeks_q1)\n```\n\n```{r summary_train_test_q1}\n#| echo: false\n\nsummary_table_q1_ts <- tibble(\n  Set = c(\"Training (Q1 2025)\", \"Testing (Q1 2025)\"),\n  Observations = c(nrow(train_q1), nrow(test_q1)),\n  Date_Range = c(\n    paste(min(train_q1$date), \"to\", max(train_q1$date)),\n    paste(min(test_q1$date), \"to\", max(test_q1$date))\n  )\n)\n\nkable(summary_table_q1_ts,\n      caption = \"Train/Test Summary – Q1 2025\") %>%\n  kable_styling(latex_options = c(\"striped\", \"hold_position\"))\n```\n\n# Build Predictive Models\n\n## Model 1: Baseline (Time + Weather) — Q1 2025\n\n```{r model1_q1}\ntrain_q1 <- train_q1 %>%\n  mutate(dotw_simple = factor(dotw, \n                              levels = c(\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Fri\",\"Sat\",\"Sun\")))\n\ncontrasts(train_q1$dotw_simple) <- contr.treatment(7)\n\nmodel1_q1 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple +\n    Temperature + Precipitation,\n  data = train_q1\n)\n```\n\n## Model 2: Add Temporal Lags — Q1 2025\n\n```{r model2_q1}\nmodel2_q1 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple +\n    Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day,\n  data = train_q1\n)\n```\n\n## Model 3: Add Demographics — Q1 2025\n\n```{r model3_q1}\nmodel3_q1 <- lm(\n  Trip_Count ~ \n    as.factor(hour) +\n    dotw_simple +\n    Temperature +\n    Precipitation +\n    lag1Hour +\n    lag3Hours +\n    lag1day +\n    Med_Inc.x +\n    Percent_Taking_Transit.x +\n    Percent_White.x,\n  data = train_q1\n)\n```\n\n## Model 4: Add Station Fixed Effects — Q1 2025\n\n```{r model4_q1}\nmodel4_q1 <- lm(\n  Trip_Count ~ \n    as.factor(hour) +\n    dotw_simple +\n    Temperature +\n    Precipitation +\n    lag1Hour +\n    lag3Hours +\n    lag1day +\n    Med_Inc.x +\n    Percent_Taking_Transit.x +\n    Percent_White.x +\n    as.factor(start_station),\n  data = train_q1\n)\n```\n\n## Model 5: Add Rush Hour Interaction — Q1 2025\n\n```{r model5_q1}\ntrain_q1$month <- factor(train_q1$month, levels = c(\"Jan\",\"Feb\",\"Mar\"))\ntest_q1$month  <- factor(test_q1$month, levels = levels(train_q1$month))\n\nmodel5_q1 <- lm(\n  Trip_Count ~ \n    as.factor(hour) +\n    dotw_simple +\n    Temperature +\n    Precipitation +\n    lag1Hour +\n    lag3Hours +\n    lag1day +\n    rush_hour +\n    month +\n    Med_Inc.x +\n    Percent_Taking_Transit.x +\n    Percent_White.x +\n    as.factor(start_station) +\n    rush_hour * weekend,\n  data = train_q1\n)\n```\n\n# Model Evaluation\n\n## Calculate Predictions and MAE — Q1 2025\n\n```{r calculate_mae_q1}\ntest_q1$month <- factor(test_q1$month, levels = model5_q1$xlevels$month)\n\ntest_q1 <- test_q1 %>%\n  mutate(dotw_simple = factor(dotw,\n                              levels = c(\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Fri\",\"Sat\",\"Sun\")))\n\ncontrasts(test_q1$dotw_simple) <- contr.treatment(7)\n\ntest_q1 <- test_q1 %>%\n  mutate(\n    pred1_q1 = predict(model1_q1, newdata = test_q1),\n    pred2_q1 = predict(model2_q1, newdata = test_q1),\n    pred3_q1 = predict(model3_q1, newdata = test_q1),\n    pred4_q1 = predict(model4_q1, newdata = test_q1),\n    pred5_q1 = predict(model5_q1, newdata = test_q1)\n  )\n\nmae_results_q1 <- tibble(\n  Model = c(\n    \"1. Time + Weather\",\n    \"2. + Temporal Lags\",\n    \"3. + Demographics\",\n    \"4. + Station FE\",\n    \"5. + Rush Hour Interaction\"\n  ),\n  MAE = c(\n    mean(abs(test_q1$Trip_Count - test_q1$pred1_q1), na.rm = TRUE),\n    mean(abs(test_q1$Trip_Count - test_q1$pred2_q1), na.rm = TRUE),\n    mean(abs(test_q1$Trip_Count - test_q1$pred3_q1), na.rm = TRUE),\n    mean(abs(test_q1$Trip_Count - test_q1$pred4_q1), na.rm = TRUE),\n    mean(abs(test_q1$Trip_Count - test_q1$pred5_q1), na.rm = TRUE)\n  )\n)\n\nkable(mae_results_q1,\n      digits = 2,\n      caption = \"Mean Absolute Error by Model (Q1 2025 Test Set)\",\n      col.names = c(\"Model\", \"MAE (trips)\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\",\"hover\"))\n```\n\n## Visualize Model Comparison — Q1 2025\n\n```{r compare_models_q1}\nggplot(mae_results_q1, aes(x = reorder(Model, -MAE), y = MAE)) +\n  geom_col(fill = \"#3182bd\", alpha = 0.8) +\n  geom_text(aes(label = round(MAE, 2)), vjust = -0.5) +\n  labs(\n    title = \"Model Performance Comparison — Q1 2025\",\n    subtitle = \"Lower MAE = Better Predictions\",\n    x = \"Model\",\n    y = \"Mean Absolute Error (trips)\"\n  ) +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n# Space- Time Error Analysis\n\n## Observed vs. Predicted — Q1 2025 (Using Model 2)\n\n```{r obs_vs_pred_q1}\ntest_q1 <- test_q1 %>%\n  mutate(\n    error_q1     = Trip_Count - pred2_q1,\n    abs_error_q1 = abs(error_q1),\n    time_of_day_q1 = case_when(\n      hour < 7                  ~ \"Overnight\",\n      hour >= 7 & hour < 10     ~ \"AM Rush\",\n      hour >= 10 & hour < 15    ~ \"Mid-Day\",\n      hour >= 15 & hour <= 18   ~ \"PM Rush\",\n      hour > 18                 ~ \"Evening\"\n    )\n  )\n\nggplot(test_q1, aes(x = Trip_Count, y = pred2_q1)) +\n  geom_point(alpha = 0.2, color = \"#3182bd\") +\n  geom_abline(slope = 1, intercept = 0, color = \"red\", linewidth = 1) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"darkgreen\") +\n  facet_grid(weekend ~ time_of_day_q1) +\n  labs(\n    title = \"Observed vs. Predicted Trips — Q1 2025\",\n    x = \"Observed Trips\",\n    y = \"Predicted Trips\"\n  ) +\n  plotTheme\n```\n\n##Spatial Error Patterns — Q1 2025\n\n```{r spatial_errors_q1}\nstation_errors_q1 <- test_q1 %>%\n  group_by(start_station, start_lat.x, start_lon.x) %>%\n  summarize(\n    MAE_q1         = mean(abs_error_q1, na.rm = TRUE),\n    avg_demand_q1  = mean(Trip_Count, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  filter(!is.na(start_lat.x), !is.na(start_lon.x))\n\np1_q1 <- ggplot() +\n  geom_sf(data = philly_census_q1, fill = \"grey95\", color = \"white\", size = 0.2) +\n  geom_point(\n    data = station_errors_q1,\n    aes(x = start_lon.x, y = start_lat.x, color = MAE_q1),\n    size = 3.5,\n    alpha = 0.7\n  ) +\n  scale_color_viridis(\n    option = \"plasma\",\n    name = \"MAE (trips)\",\n    direction = -1\n  ) +\n  labs(title = \"Prediction Errors — Q1 2025\") +\n  mapTheme +\n  theme(legend.position = \"bottom\")\n\np2_q1 <- ggplot() +\n  geom_sf(data = philly_census_q1, fill = \"grey95\", color = \"white\", size = 0.2) +\n  geom_point(\n    data = station_errors_q1,\n    aes(x = start_lon.x, y = start_lat.x, color = avg_demand_q1),\n    size = 3.5,\n    alpha = 0.7\n  ) +\n  scale_color_viridis(\n    option = \"viridis\",\n    name = \"Avg Demand (trips/hr)\",\n    direction = -1\n  ) +\n  labs(title = \"Average Demand — Q1 2025\") +\n  mapTheme +\n  theme(legend.position = \"bottom\")\n\ngrid.arrange(p1_q1, p2_q1, ncol = 2)\n```\n\n## Temporal Error Patterns — Q1 2025\n\n```{r temporal_errors_q1}\ntemporal_errors_q1 <- test_q1 %>%\n  group_by(time_of_day_q1, weekend) %>%\n  summarize(\n    MAE_q1 = mean(abs_error_q1, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  mutate(day_type_q1 = ifelse(weekend == 1, \"Weekend\", \"Weekday\"))\n\nggplot(temporal_errors_q1, aes(x = time_of_day_q1, y = MAE_q1, fill = day_type_q1)) +\n  geom_col(position = \"dodge\") +\n  scale_fill_manual(values = c(\"Weekday\" = \"#08519c\", \"Weekend\" = \"#6baed6\")) +\n  labs(\n    title = \"Prediction Errors by Time of Day — Q1 2025\",\n    x = \"Time of Day\",\n    y = \"Mean Absolute Error (trips)\"\n  ) +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n## Errors vs. Demographics — Q1 2025\n\n```{r errors_demographics_q1}\nstation_errors_demo_q1 <- station_errors_q1 %>%\n  left_join(\n    station_attributes_q1 %>%\n      select(start_station, Med_Inc, Percent_Taking_Transit, Percent_White),\n    by = \"start_station\"\n  ) %>%\n  filter(!is.na(Med_Inc))\n\np1_q1 <- ggplot(station_errors_demo_q1, aes(x = Med_Inc, y = MAE_q1)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  scale_x_continuous(labels = scales::dollar) +\n  labs(x = \"Median Income\", y = \"MAE\") +\n  plotTheme\n\np2_q1 <- ggplot(station_errors_demo_q1, aes(x = Percent_Taking_Transit, y = MAE_q1)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(x = \"% Taking Transit\", y = \"MAE\") +\n  plotTheme\n\np3_q1 <- ggplot(station_errors_demo_q1, aes(x = Percent_White, y = MAE_q1)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(x = \"% White\", y = \"MAE\") +\n  plotTheme\n\ngrid.arrange(p1_q1, p2_q1, p3_q1, ncol = 2)\n```\n\n# INDEGO TRIP DATA Q2 2024\n\n## Load Indego Trip Data (Q2 2024)\n\n```{r}\n#| echo: false\n#| message: false \n#| output: false\n# Read Q1 2025 data\nindego <- read_csv(here(\"C:/Users/chloe.robinson/Desktop/PENN/FALL 2025/Public Policy Analytics/Week 1/portfolio-setup-chloelr/Labs/Lab 5/Data/indego-trips-2024-q2.csv\"))\n\n# Quick look at the data\nglimpse(indego)\n```\n\n```{r}\n#| echo: false\n#| results: hide\n#| message: false\n#| warning: false\n# How many trips?\ncat(\"Total trips in Q2 2024:\", nrow(indego), \"\\n\")\n\n# Date range\ncat(\"Date range:\", \n    min(mdy_hm(indego$start_time)), \"to\", \n    max(mdy_hm(indego$start_time)), \"\\n\")\n\n# How many unique stations?\ncat(\"Unique start stations:\", length(unique(indego$start_station)), \"\\n\")\n\n# Trip types\ntable(indego$trip_route_category)\n\n# Passholder types\ntable(indego$passholder_type)\n\n# Bike types\ntable(indego$bike_type)\n```\n\n```{r summary_table}\n#| echo: false\n#| message: false\n#| warning: false\n\nsummary_table <- tibble(\n  `Total Trips`           = nrow(indego),\n  `Date Range Start`      = min(mdy_hm(indego$start_time)),\n  `Date Range End`        = max(mdy_hm(indego$start_time)),\n  `Unique Start Stations` = length(unique(indego$start_station))\n)\n\nkable(summary_table, caption = \"Summary of Indego Trip Data\") |>\n  kable_styling(latex_options = \"hold_position\")\n```\n\n## Create Time Bins\n\nWe need to aggregate trips into hourly intervals for our panel data structure.\n\n```{r}\nindego <- indego %>%\n  mutate(\n    # Parse datetime\n    start_datetime = mdy_hm(start_time),\n    end_datetime = mdy_hm(end_time),\n    \n    # Create hourly bins\n    interval60 = floor_date(start_datetime, unit = \"hour\"),\n    \n    # Extract time features\n    week = week(interval60),\n    month = month(interval60, label = TRUE),\n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    date = as.Date(interval60),\n    \n    # Create useful indicators\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n```\n\n```{r}\n#| echo: false\nindego %>%\n  select(start_datetime, interval60, week, dotw, hour, weekend) %>%\n  head(10) %>%\n  kable(caption = \"Preview of temporal features\") %>%\n  kable_styling(latex_options = c(\"striped\", \"hold_position\"))\n```\n\n------------------------------------------------------------------------\n\n# Exploratory Analysis\n\n## Trips Over Time\n\n```{r}\n# Daily trip counts\ndaily_trips <- indego %>%\n  group_by(date) %>%\n  summarize(trips = n())\n\nggplot(daily_trips, aes(x = date, y = trips)) +\n  geom_line(color = \"#3182bd\", linewidth = 1) +\n  geom_smooth(se = FALSE, color = \"red\", linetype = \"dashed\") +\n  labs(\n    title = \"Indego Daily Ridership - Q2 2024\",\n    subtitle = \"Spring Demand Paters in Philadelphia\",\n    x = \"Date\",\n    y = \"Daily Trips\",\n    caption = \"Source: Indego bike share\"\n  ) +\n  plotTheme\n```\n\nIndego ridership increases at a steady pace from April through June, showing a clear upward seasonal trend as the weather improves. Although overall ridership rises over time, there are occasional dips and highs that likely reflect bad weather or special events in Philadelphia.\n\n## Hourly Patterns\n\n```{r hourly_patterns}\n# Average trips by hour and day type\nhourly_patterns <- indego %>%\n  group_by(hour, weekend) %>%\n  summarize(avg_trips = n() / n_distinct(date)) %>%\n  mutate(day_type = ifelse(weekend == 1, \"Weekend\", \"Weekday\"))\n\nggplot(hourly_patterns, aes(x = hour, y = avg_trips, color = day_type)) +\n  geom_line(linewidth = 1.2) +\n  scale_color_manual(values = c(\"Weekday\" = \"#08519c\", \"Weekend\" = \"#6baed6\")) +\n  labs(\n    title = \"Average Hourly Ridership Patterns\",\n    subtitle = \"Clear commute patterns on weekdays\",\n    x = \"Hour of Day\",\n    y = \"Average Trips per Hour\",\n    color = \"Day Type\"\n  ) +\n  plotTheme\n```\n\nThe chart shows a strong correlation between commuting times and ridership during the weekday. There is a clear spike during the morning commute time during the week at 9am, and an even higher spike in ridership during the evening peak commute time, around 5-6pm. In contrast, the weekend pattern does not show sharp ridership peaks, instead has a steady ridership rises later in the morning, stays spread out across the afternoon, and begins to decline at 3pm.\n\n## Top Stations\n\n```{r top_stations}\n# Most popular origin stations\ntop_stations <- indego %>%\n  count(start_station, start_lat, start_lon, name = \"trips\") %>%\n  arrange(desc(trips)) %>%\n  head(10)\n```\n\n```{r top_stations_table}\n#| echo: false\nkable(top_stations, \n      caption = \"Top 10 Indego Stations by Trip Origins\",\n      format.args = list(big.mark = \",\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n------------------------------------------------------------------------\n\n# Get Philadelphia Spatial Context\n\n## Load Philadelphia Census Data + Map Context\n\n```{r load_census}\n#| echo: false\n#| results: hide\n#| message: false\n#| warning: false\n\n# Get Philadelphia census tracts\nphilly_census <- get_acs(\n  geography = \"tract\",\n  variables = c(\n    \"B01003_001\",  # Total population\n    \"B19013_001\",  # Median household income\n    \"B08301_001\",  # Total commuters\n    \"B08301_010\",  # Commute by transit\n    \"B02001_002\",  # White alone\n    \"B25077_001\"   # Median home value\n  ),\n  state = \"PA\",\n  county = \"Philadelphia\",\n  year = 2022,\n  geometry = TRUE,\n  output = \"wide\"\n) %>%\n  rename(\n    Total_Pop = B01003_001E,\n    Med_Inc = B19013_001E,\n    Total_Commuters = B08301_001E,\n    Transit_Commuters = B08301_010E,\n    White_Pop = B02001_002E,\n    Med_Home_Value = B25077_001E\n  ) %>%\n  mutate(\n    Percent_Taking_Transit = (Transit_Commuters / Total_Commuters) * 100,\n    Percent_White = (White_Pop / Total_Pop) * 100\n  ) %>%\n  st_transform(crs = 4326)  # WGS84 for lat/lon matching\n\n# Check the data\nglimpse(philly_census)\n```\n\n## Map Philadelphia Context\n\n```{r map_philly}\n# Map median income\nggplot() +\n  geom_sf(data = philly_census, aes(fill = Med_Inc), color = NA) +\n  scale_fill_viridis(\n    option = \"viridis\",\n    name = \"Median\\nIncome\",\n    labels = scales::dollar\n  ) +\n  labs(\n    title = \"Philadelphia Median Household Income by Census Tract\",\n    subtitle = \"Context for understanding bike share demand patterns\"\n  ) +\n  # Stations \n  geom_point(\n    data = indego,\n    aes(x = start_lon, y = start_lat),\n    color = \"red\", size = 0.25, alpha = 0.6\n  ) +\n  mapTheme\n```\n\n## Join Census Data to Stations\n\nWe'll spatially join census characteristics to each bike station.\n\n```{r join_census_to_stations}\n# Create sf object for stations\nstations_sf <- indego %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  st_as_sf(coords = c(\"start_lon\", \"start_lat\"), crs = 4326)\n\n# Spatial join to get census tract for each station\nstations_census <- st_join(stations_sf, philly_census, left = TRUE) %>%\n  st_drop_geometry()\n\n# Look at the result - investigate whether all of the stations joined to census data\n\nstations_for_map <- indego %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  left_join(\n    stations_census %>% select(start_station, Med_Inc),\n    by = \"start_station\"\n  ) %>%\n  mutate(has_census = !is.na(Med_Inc))\n\n# Add back to trip data\nindego_census <- indego %>%\n  left_join(\n    stations_census %>% \n      select(start_station, Med_Inc, Percent_Taking_Transit, \n             Percent_White, Total_Pop),\n    by = \"start_station\"\n  )\n```\n\n```{r join_census_to_stations2}\n#| echo: false\n# Prepare data for visualization\nstations_for_map <- indego %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  left_join(\n    stations_census %>% select(start_station, Med_Inc),\n    by = \"start_station\"\n  ) %>%\n  mutate(has_census = !is.na(Med_Inc))\n\n# Create the map showing problem stations\nggplot() +\n  geom_sf(data = philly_census, aes(fill = Med_Inc), color = \"white\", size = 0.1) +\n  scale_fill_viridis(\n    option = \"viridis\",\n    name = \"Median\\nIncome\",\n    labels = scales::dollar,\n    na.value = \"grey90\"\n  ) +\n  # Stations with census data (small grey dots)\n  geom_point(\n    data = stations_for_map %>% filter(has_census),\n    aes(x = start_lon, y = start_lat),\n    color = \"grey30\", size = 1, alpha = 0.6\n  ) +\n  # Stations WITHOUT census data (red X marks the spot)\n  geom_point(\n    data = stations_for_map %>% filter(!has_census),\n    aes(x = start_lon, y = start_lat),\n    color = \"red\", size = 1, shape = 4, stroke = 1.5\n  ) +\n  labs(\n    title = \"Philadelphia Median Household Income by Census Tract\",\n    subtitle = \"Indego stations shown (RED = no census data match)\",\n    caption = \"Red X marks indicate stations that didn't join to census tracts\"\n  ) +\n  mapTheme\n```\n\n# Dealing with missing data\n\nWe need to decide what to do with the non-residential bike share stations. For this example, we are going to remove them -- this is not necessarily the right way to do things always, but for the sake of simplicity, we are narrowing our scope to only stations in residential neighborhoods. We might opt to create a separate model for non-residential stations..\n\n```{r}\n# Identify which stations to keep\nvalid_stations <- stations_census %>%\n  filter(!is.na(Med_Inc)) %>%\n  pull(start_station)\n\n# Filter trip data to valid stations only\nindego_census <- indego %>%\n  filter(start_station %in% valid_stations) %>%\n  left_join(\n    stations_census %>% \n      select(start_station, Med_Inc, Percent_Taking_Transit, \n             Percent_White, Total_Pop),\n    by = \"start_station\"\n  )\n\n```\n\n# Get Weather Data\n\nWeather significantly affects bike share demand! Let's get hourly weather for Philadelphia.\n\n```{r get_weather}\n# Get weather from Philadelphia International Airport (KPHL)\n# This covers Q2 2024: April 1 - June 30\nweather_data <- riem_measures(\n  station = \"PHL\",  # Philadelphia International Airport\n  date_start = \"2024-04-01\",\n  date_end = \"2024-06-30\"\n)\n\n# Process weather data\nweather_processed <- weather_data %>%\n  mutate(\n    interval60 = floor_date(valid, unit = \"hour\"),\n    Temperature = tmpf,  # Temperature in Fahrenheit\n    Precipitation = ifelse(is.na(p01i), 0, p01i),  # Hourly precip in inches\n    Wind_Speed = sknt  # Wind speed in knots\n  ) %>%\n  select(interval60, Temperature, Precipitation, Wind_Speed) %>%\n  distinct()\n\n# Check for missing hours and interpolate if needed\nweather_complete <- weather_processed %>%\n  complete(interval60 = seq(min(interval60), max(interval60), by = \"hour\")) %>%\n  fill(Temperature, Precipitation, Wind_Speed, .direction = \"down\")\n```\n\n## Visualize Weather Patterns\n\n```{r visualize_weather}\n#| echo: false\nggplot(weather_complete, aes(x = interval60, y = Temperature)) +\n  geom_line(color = \"#3182bd\", alpha = 0.7) +\n  geom_smooth(se = FALSE, color = \"red\") +\n  labs(\n    title = \"Philadelphia Temperature - Q2 2024\",\n    subtitle = \"Winter to early spring transition\",\n    x = \"Date\",\n    y = \"Temperature (°F)\"\n  ) +\n  plotTheme\n```\n\n------------------------------------------------------------------------\n\n# Create Space-Time Panel\n\n## Aggregate Trips to Station-Hour Level\n\n```{r aggregate_trips_1}\n# Count trips by station-hour\ntrips_panel <- indego_census %>%\n  group_by(interval60, start_station, start_lat, start_lon,\n           Med_Inc, Percent_Taking_Transit, Percent_White, Total_Pop) %>%\n  summarize(Trip_Count = n()) %>%\n  ungroup()\n```\n\n```{r aggregate_trips}\n#| echo: false\nsummary_counts <- tibble(\n  Metric = c(\n    \"Total Station-Hour Observations\",\n    \"Unique Stations\",\n    \"Unique Hours\"\n  ),\n  Value = c(\n    nrow(trips_panel),\n    length(unique(trips_panel$start_station)),\n    length(unique(trips_panel$interval60))\n  )\n)\n\nsummary_counts %>%\n  kable(\n    caption = \"Summary of Panel Structure\",\n    col.names = c(\"Metric\", \"Value\"),\n    format.args = list(big.mark = \",\")\n  ) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n## Create Complete Panel Structure\n\nNot every station has trips every hour. We need a **complete panel** where every station-hour combination exists (even if Trip_Count = 0).\n\n```{r complete_panel}\n# Calculate expected panel size\nn_stations <- length(unique(trips_panel$start_station))\nn_hours <- length(unique(trips_panel$interval60))\nexpected_rows <- n_stations * n_hours\n```\n\n```{r complete_panel_summary}\n#| echo: false\n# Create summary table\npanel_summary <- tibble(\n  Metric = c(\"Expected panel rows\",\n             \"Current rows\",\n             \"Missing rows\"),\n  Value = c(expected_rows,\n            nrow(trips_panel),\n            expected_rows - nrow(trips_panel))\n)\n\n# Format numbers with commas\npanel_summary$Value <- format(panel_summary$Value, big.mark = \",\")\n\n# Display clean table\nkable(panel_summary,\n      caption = \"Completeness of Panel Structure\") |>\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n```{r complete_panel_summary_2}\n# Create complete panel\nstudy_panel <- expand.grid(\n  interval60 = unique(trips_panel$interval60),\n  start_station = unique(trips_panel$start_station)\n) %>%\n  # Join trip counts\n  left_join(trips_panel, by = c(\"interval60\", \"start_station\")) %>%\n  # Replace NA trip counts with 0\n  mutate(Trip_Count = replace_na(Trip_Count, 0))\n\n# Fill in station attributes (they're the same for all hours)\nstation_attributes <- trips_panel %>%\n  group_by(start_station) %>%\n  summarize(\n    start_lat = first(start_lat),\n    start_lon = first(start_lon),\n    Med_Inc = first(Med_Inc),\n    Percent_Taking_Transit = first(Percent_Taking_Transit),\n    Percent_White = first(Percent_White),\n    Total_Pop = first(Total_Pop)\n  )\n\nstudy_panel <- study_panel %>%\n  left_join(station_attributes, by = \"start_station\")\n```\n\n```{r complete_panel_summary_3}\n#| echo: false\ncomplete_panel_summary <- tibble(\nMetric = \"Complete panel rows\",\nValue = format(nrow(study_panel), big.mark = \",\")\n)\n\nkable(complete_panel_summary,\ncaption = \"Final Panel Size After Completion\") |>\nkable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n## Add Time Features\n\n```{r add_time_features}\nstudy_panel <- study_panel %>%\n  mutate(\n    week = week(interval60),\n    month = month(interval60, label = TRUE),\n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    date = as.Date(interval60),\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n```\n\n## Join Weather Data\n\n```{r join_weather}\nstudy_panel <- study_panel %>%\n  left_join(weather_complete, by = \"interval60\")\n```\n\n------------------------------------------------------------------------\n\n# Create Temporal Lag Variables\n\nThe key innovation for space-time prediction: **past demand predicts future demand**.\n\n## Why Lags?\n\nIf there were 15 bike trips from Station A at 8:00 AM, there will probably be \\~15 trips at 9:00 AM. We can use this temporal persistence to improve predictions.\n\n```{r create_lags}\n# Sort by station and time\nstudy_panel <- study_panel %>%\n  arrange(start_station, interval60)\n\n# Create lag variables WITHIN each station\nstudy_panel <- study_panel %>%\n  group_by(start_station) %>%\n  mutate(\n    lag1Hour = lag(Trip_Count, 1),\n    lag2Hours = lag(Trip_Count, 2),\n    lag3Hours = lag(Trip_Count, 3),\n    lag12Hours = lag(Trip_Count, 12),\n    lag1day = lag(Trip_Count, 24)\n  ) %>%\n  ungroup()\n\n# Remove rows with NA lags (first 24 hours for each station)\nstudy_panel_complete <- study_panel %>%\n  filter(!is.na(lag1day))\n\nstudy_panel_complete <- study_panel_complete %>%\n  mutate(\n    month = factor(month, levels = c(\"Apr\", \"May\", \"Jun\")),\n    dotw  = factor(dotw,  levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"))\n  )\n```\n\n## Visualize Lag Correlations\n\n```{r lag_correlations}\n# Sample one station to visualize\nexample_station <- study_panel_complete %>%\n  filter(start_station == first(start_station)) %>%\n  head(168)  # One week\n\n# Plot actual vs lagged demand\nggplot(example_station, aes(x = interval60)) +\n  geom_line(aes(y = Trip_Count, color = \"Current\"), linewidth = 1) +\n  geom_line(aes(y = lag1Hour, color = \"1 Hour Ago\"), linewidth = 1, alpha = 0.7) +\n  geom_line(aes(y = lag1day, color = \"24 Hours Ago\"), linewidth = 1, alpha = 0.7) +\n  scale_color_manual(values = c(\n    \"Current\" = \"#08519c\",\n    \"1 Hour Ago\" = \"#3182bd\",\n    \"24 Hours Ago\" = \"#6baed6\"\n  )) +\n  labs(\n    title = \"Temporal Lag Patterns at One Station\",\n    subtitle = \"Past demand predicts future demand\",\n    x = \"Date-Time\",\n    y = \"Trip Count\",\n    color = \"Time Period\"\n  ) +\n  plotTheme\n```\n\n------------------------------------------------------------------------\n\n# Temporal Train/Test Split\n\n**CRITICAL:** We must train on PAST data and test on FUTURE data!\n\n## Why Temporal Validation Matters\n\nIn real operations, at 6:00 AM on March 15, we need to predict demand for March 15-31. We have data from Jan 1 - March 14, but NOT from March 15-31 (it hasn't happened yet!).\n\n**Wrong approach:** Train on weeks 10-13, test on weeks 1-9 (predicting past from future!)\n\n**Correct approach:** Train on weeks 1-9, test on weeks 10-13 (predicting future from past)\n\n```{r temporal_split}\n# Split by week for Q2 2024\n# Q2 has weeks 14–26 (April–June)\n# Train on weeks 14–21 (April–late May)\n# Test on weeks 22–26 (mostly June)\n\ntrain_weeks <- 14:21\ntest_weeks  <- 22:26\n\n# Stations active in BOTH early (train) and late (test) periods\nearly_stations <- study_panel_complete %>%\n  filter(week %in% train_weeks, Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\nlate_stations <- study_panel_complete %>%\n  filter(week %in% test_weeks, Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\ncommon_stations <- intersect(early_stations, late_stations)\n\n# Keep only common stations\nstudy_panel_q2 <- study_panel_complete %>%\n  filter(start_station %in% common_stations)\n\n# Now create train/test split\ntrain <- study_panel_q2 %>%\n  filter(week %in% train_weeks)\n\ntest <- study_panel_q2 %>%\n  filter(week %in% test_weeks)\n```\n\n```{r summary 2}\n#| echo: false\nsummary_table <- tibble(\n  Set = c(\"Training\", \"Testing\"),\n  Observations = c(nrow(train), nrow(test)),\n  Date_Range = c(\n    paste(min(train$date), \"to\", max(train$date)),\n    paste(min(test$date), \"to\", max(test$date))\n  )\n)\n\nkable(summary_table, format = \"latex\", booktabs = TRUE, caption = \"Train/Test Summary\") %>%\n  kable_styling(latex_options = c(\"striped\", \"hold_position\"))\n```\n\n------------------------------------------------------------------------\n\n# Build Predictive Models\n\nWe'll build 5 models with increasing complexity to see what improves predictions.\n\n## Model 1: Baseline (Time + Weather)\n\n```{r model1}\n\n# Create day of week factor with treatment (dummy) coding\ntrain <- train %>%\n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\n# Set contrasts to treatment coding (dummy variables)\ncontrasts(train$dotw_simple) <- contr.treatment(7)\n\n# Now run the model\nmodel1 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation,\n  data = train\n)\n\n```\n\nThe model uses Monday as the baseline. Each coefficient represents the difference in expected trips per station-hour compared to Monday - dow_simple2 = Tuesday..\n\n**Weekday Pattern (Tue-Fri):**\n\n-   Weekday effects range from –0.063 to +0.016.\n-   No weekday has a positive, strong increase, unlike your example.\n-   Thursday is the only weekday above baseline.\n-   Tuesday, Wednesday, and Friday are all slightly below Monday.\n\n**Weekend Pattern (Sat-Sun):**\n\n-   Both weekend days show substantial drops relative to Monday.\n-   Sunday has the largest negative effect (–0.112).\n-   This indicates significantly lower station-hour activity on weekends.\n\n**Hourly Interpretation**\n\nAcross the 24-hour day, activity is lowest between hours 1–4, where trips fall slightly below the midnight baseline (with coefficients between -0.078 and -0.096). Activity begins to rise at hour 5 (+0.033) and increases sharply through the morning commute, with strong positive effects at hours 6–9, including a substantial morning peak at hour 8 (+0.851) and sustained high demand at hour 9 (+0.637). Midday hours (10–14) maintain moderately elevated trip counts, ranging from +0.535 to +0.643. In the afternoon, demand climbs again, rising through hours 15–16 and reaching the highest level of the entire day at hour 17 (+1.161), indicating a very strong evening peak. Activity remains high at hour 18 (+0.917) before gradually declining across the evening hours 19–22 (from +0.672 down to +0.186). By hour 23, demand tapers to a modest +0.065—still slightly above the midnight baseline but representing the transition into late-night low activity.\n\nIsn't this fun!\n\n## Model 2: Add Temporal Lags\n\n```{r model2}\nmodel2 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day,\n  data = train\n)\n```\n\nThe inclusion of temporal lags substantially improved the model’s explanatory power, raising the adjusted R² from approximately 0.116 to 0.348, which reflects a nearly threefold increase in explained variation. This improvement occurs because bike-share demand is highly autocorrelated: stations that experience high or low usage in one hour tend to show similar patterns in the following hours, and usage at the same hour on the previous day is also strongly predictive. The lagged variables, particularly the one-hour lag and the three-hour and one-day lags, capture these short-term and daily cyclical patterns that the hour-of-day and day-of-week predictors alone can't do. As a result, the model better reflects the underlying temporal structure of bike demand, leading to smaller residuals and a much stronger overall fit.\n\n## Model 3: Add Demographics\n\n```{r model3}\n#| results: hide\n#| message: false\n#| warning: false\n\nmodel3 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day +\n    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y,\n  data = train\n)\n\nsummary(model3)\n```\n\nThe addition of demographic variables did not improve model fit; in fact, the adjusted R² declined from about 0.348 in the temporal-lag model to roughly 0.237 after including median income, transit use, and racial composition. This reduction occurs primarily because adding demographics caused the loss of over 270,000 observations due to missing data, leaving the model trained on less than one-third of the original sample. With far fewer observations, the hour-to-hour temporal structure that drives trip volume becomes harder to estimate precisely, and the remaining sample may not fully represent the full behavioral patterns across the system. Although two demographic predictors, percent taking transit and percent white are statistically significant, their effect sizes are small relative to the strong temporal autocorrelation captured by the lagged variables. As a result, the demographic-augmented model explains less variance overall, not because demographics are irrelevant, but because the loss of data outweighs any modest predictive gains they could have contributed.\n\n## Model 4: Add Station Fixed Effects\n\n```{r model4}\nmodel4 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day +\n    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y +\n    as.factor(start_station),\n  data = train\n)\n\n# Summary too long with all station dummies, just show key metrics\ncat(\"Model 4 R-squared:\", summary(model4)$r.squared, \"\\n\")\ncat(\"Model 4 Adj R-squared:\", summary(model4)$adj.r.squared, \"\\n\")\n```\n\nAdding station fixed effects allows the model to account for persistent, station-specific differences in baseline trip demand that are not explained by hourly patterns, day-of-week effects, weather, lags, or demographics. Some stations are inherently busier because they are located in dense commercial districts, near major transit hubs, or along popular commuting corridors, while others serve quieter residential or peripheral areas with consistently lower usage. By including a dummy variable for each station, the model absorbs these stable location-level characteristics, effectively letting every station have its own intercept and preventing unobserved spatial differences from biasing the other coefficients. Although this raises the R-squared relative to the demographics-only model, the improvement is moderate because fixed effects mainly redistribute variance across stations rather than improving the model’s ability to explain within station temporal fluctuations, which are still driven primarily by the lag terms and hourly patterns.\n\n## Model 5: Add Rush Hour Interaction\n\n```{r model5}\ntrain$month <- factor(train$month, levels = c(\"Apr\", \"May\", \"Jun\"))\ntest$month <- factor(test$month, levels = levels(train$month))\n\nmodel5 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day + rush_hour + month +\n    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y +\n    as.factor(start_station) +\n    rush_hour * weekend,  # Rush hour effects different on weekends\n  data = train\n)\n```\n\nModel 5 adds a rush_hour × weekend interaction to allow peak-period effects to differ between weekdays and weekends. This recognizes that weekday rush hours reflect strong commuting patterns, while weekend usage is more diffuse and less time-sensitive. By including this interaction, along with month fixed effects, the model captures important behavioral differences in how riders use the system across days and times, refining the temporal structure established in earlier models.\n\n------------------------------------------------------------------------\n\n# Model Evaluation\n\n## Calculate Predictions and MAE\n\n```{r calculate_mae}\n# Get predictions on test set\n\n# Make sure month in TEST has the same levels as train\ntest$month <- factor(test$month, levels = model5$xlevels$month)\n\n# Create day of week factor with treatment (dummy) coding\ntest <- test %>%\n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\n# Set contrasts to treatment coding (dummy variables)\ncontrasts(test$dotw_simple) <- contr.treatment(7)\n\ntest <- test %>%\n  mutate(\n    pred1 = predict(model1, newdata = test),\n    pred2 = predict(model2, newdata = test),\n    pred3 = predict(model3, newdata = test),\n    pred4 = predict(model4, newdata = test),\n    pred5 = predict(model5, newdata = test)\n  )\n\n# Calculate MAE for each model\nmae_results <- data.frame(\n  Model = c(\n    \"1. Time + Weather\",\n    \"2. + Temporal Lags\",\n    \"3. + Demographics\",\n    \"4. + Station FE\",\n    \"5. + Rush Hour Interaction\"\n  ),\n  MAE = c(\n    mean(abs(test$Trip_Count - test$pred1), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred2), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred3), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred4), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred5), na.rm = TRUE)\n  )\n)\n\nkable(mae_results, \n      digits = 2,\n      caption = \"Mean Absolute Error by Model (Test Set)\",\n      col.names = c(\"Model\", \"MAE (trips)\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n## Visualize Model Comparison\n\n```{r compare_models}\nggplot(mae_results, aes(x = reorder(Model, -MAE), y = MAE)) +\n  geom_col(fill = \"#3182bd\", alpha = 0.8) +\n  geom_text(aes(label = round(MAE, 2)), vjust = -0.5) +\n  labs(\n    title = \"Model Performance Comparison\",\n    subtitle = \"Lower MAE = Better Predictions\",\n    x = \"Model\",\n    y = \"Mean Absolute Error (trips)\"\n  ) +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n**Question:** Which features gave us the biggest improvement?\n\nFor Q2 2024, the features that helped the most were the temporal lags (Model 2). When we added the 1-hour, 3-hour, and 24-hour lag variables, the MAE dropped the most, from 0.86 down to 0.71. This makes sense because bike demand tends to repeat patterns from the previous hour or the same hour yesterday.\n\n------------------------------------------------------------------------\n\n# Space-Time Error Analysis\n\n## Observed vs. Predicted\n\nLet's use our best model (Model 2) for error analysis.\n\n```{r obs_vs_pred}\ntest <- test %>%\n  mutate(\n    error = Trip_Count - pred2,\n    abs_error = abs(error),\n    time_of_day = case_when(\n      hour < 7 ~ \"Overnight\",\n      hour >= 7 & hour < 10 ~ \"AM Rush\",\n      hour >= 10 & hour < 15 ~ \"Mid-Day\",\n      hour >= 15 & hour <= 18 ~ \"PM Rush\",\n      hour > 18 ~ \"Evening\"\n    )\n  )\n\n# Scatter plot by time and day type\nggplot(test, aes(x = Trip_Count, y = pred2)) +\n  geom_point(alpha = 0.2, color = \"#3182bd\") +\n  geom_abline(slope = 1, intercept = 0, color = \"red\", linewidth = 1) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"darkgreen\") +\n  facet_grid(weekend ~ time_of_day) +\n  labs(\n    title = \"Observed vs. Predicted Bike Trips\",\n    subtitle = \"Model 2 performance by time period\",\n    x = \"Observed Trips\",\n    y = \"Predicted Trips\",\n    caption = \"Red line = perfect predictions; Green line = actual model fit\"\n  ) +\n  plotTheme\n```\n\n**Question:** Where is the model performing well? Where is it struggling?\n\nThe model performs best during Mid-Day and Overnight hours, where points fall close to the 45° line and the green fitted line tracks the red perfect-prediction line more closely. It performs worst during AM Rush and PM Rush, especially on weekdays, where the model systematically under-predicts higher ridership and shows much wider scatter. Evening periods also show moderate under-prediction but less extreme than the rush hours.\n\n## Spatial Error Patterns\n\nAre prediction errors clustered in certain parts of Philadelphia?\n\n```{r spatial_errors}\n# Calculate MAE by station\nstation_errors <- test %>%\n  group_by(start_station, start_lat.x, start_lon.y) %>%\n  summarize(\n    MAE = mean(abs_error, na.rm = TRUE),\n    avg_demand = mean(Trip_Count, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  filter(!is.na(start_lat.x), !is.na(start_lon.y))\n\n## Create Two Maps Side-by-Side with Proper Legends (sorry these maps are ugly)\n\n# Calculate station errors\nstation_errors <- test %>%\n  filter(!is.na(pred2)) %>%\n  group_by(start_station, start_lat.x, start_lon.y) %>%\n  summarize(\n    MAE = mean(abs(Trip_Count - pred2), na.rm = TRUE),\n    avg_demand = mean(Trip_Count, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  filter(!is.na(start_lat.x), !is.na(start_lon.y))\n\n# Map 1: Prediction Errors\np1 <- ggplot() +\n  geom_sf(data = philly_census, fill = \"grey95\", color = \"white\", size = 0.2) +\n  geom_point(\n    data = station_errors,\n    aes(x = start_lon, y = start_lat, color = MAE),\n    size = 3.5,\n    alpha = 0.7\n  ) +\n  scale_color_viridis(\n    option = \"plasma\",\n    name = \"MAE\\n(trips)\",\n    direction = -1,\n    breaks = c(0.5, 1.0, 1.5),  # Fewer, cleaner breaks\n    labels = c(\"0.5\", \"1.0\", \"1.5\")\n  ) +\n  labs(title = \"Prediction Errors\",\n       subtitle = \"Higher in Center City\") +\n  mapTheme +\n  theme(\n    legend.position = \"right\",\n    legend.title = element_text(size = 10, face = \"bold\"),\n    legend.text = element_text(size = 9),\n    plot.title = element_text(size = 14, face = \"bold\"),\n    plot.subtitle = element_text(size = 10)\n  ) +\n  guides(color = guide_colorbar(\n    barwidth = 1.5,\n    barheight = 12,\n    title.position = \"top\",\n    title.hjust = 0.5\n  ))\n\n# Map 2: Average Demand\np2 <- ggplot() +\n  geom_sf(data = philly_census, fill = \"grey95\", color = \"white\", size = 0.2) +\n  geom_point(\n    data = station_errors,\n    aes(x = start_lon.y, y = start_lat.x, color = avg_demand),\n    size = 3.5,\n    alpha = 0.7\n  ) +\n  scale_color_viridis(\n    option = \"viridis\",\n    name = \"Avg\\nDemand\",\n    direction = -1,\n    breaks = c(0.5, 1.0, 1.5, 2.0, 2.5),  # Clear breaks\n    labels = c(\"0.5\", \"1.0\", \"1.5\", \"2.0\", \"2.5\")\n  ) +\n  labs(title = \"Average Demand\",\n       subtitle = \"Trips per station-hour\") +\n  mapTheme +\n  theme(\n    legend.position = \"right\",\n    legend.title = element_text(size = 10, face = \"bold\"),\n    legend.text = element_text(size = 9),\n    plot.title = element_text(size = 14, face = \"bold\"),\n    plot.subtitle = element_text(size = 10)\n  ) +\n  guides(color = guide_colorbar(\n    barwidth = 1.5,\n    barheight = 12,\n    title.position = \"top\",\n    title.hjust = 0.5\n  ))\n\n# Map 1: Prediction Errors\np1 <- ggplot() +\n  geom_sf(data = philly_census, fill = \"grey95\", color = \"white\", size = 0.1) +\n  geom_point(\n    data = station_errors,\n    aes(x = start_lon.y, y = start_lat.x, color = MAE),\n    size = 3.5,\n    alpha = 0.7\n  ) +\n  scale_color_viridis(\n    option = \"plasma\",\n    name = \"MAE (trips)\",\n    direction = -1,\n    breaks = c(0.5, 1.0, 1.5),\n    labels = c(\"0.5\", \"1.0\", \"1.5\")\n  ) +\n  labs(title = \"Prediction Errors\") +\n  mapTheme +\n  theme(\n    legend.position = \"bottom\",\n    legend.title = element_text(size = 10, face = \"bold\"),\n    legend.text = element_text(size = 9),\n    plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5)\n  ) +\n  guides(color = guide_colorbar(\n    barwidth = 12,\n    barheight = 1,\n    title.position = \"top\",\n    title.hjust = 0.5\n  ))\n\n# Map 2: Average Demand  \np2 <- ggplot() +\n  geom_sf(data = philly_census, fill = \"grey95\", color = \"white\", size = 0.1) +\n  geom_point(\n    data = station_errors,\n    aes(x = start_lon.y, y = start_lat.x, color = avg_demand),\n    size = 3.5,\n    alpha = 0.7\n  ) +\n  scale_color_viridis(\n    option = \"viridis\",\n    name = \"Avg Demand (trips/hour)\",\n    direction = -1,\n    breaks = c(0.5, 1.0, 1.5, 2.0, 2.5),\n    labels = c(\"0.5\", \"1.0\", \"1.5\", \"2.0\", \"2.5\")\n  ) +\n  labs(title = \"Average Demand\") +\n  mapTheme +\n  theme(\n    legend.position = \"bottom\",\n    legend.title = element_text(size = 10, face = \"bold\"),\n    legend.text = element_text(size = 9),\n    plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5)\n  ) +\n  guides(color = guide_colorbar(\n    barwidth = 12,\n    barheight = 1,\n    title.position = \"top\",\n    title.hjust = 0.5\n  ))\n\n# Combine\ngrid.arrange(\n  p1, p2,\n  ncol = 2\n  )\n```\n\n**Question:** Do you see spatial clustering of errors? What neighborhoods have high errors?\n\nYes, there is a clear spatial clustering of errors. The highest prediction errors occur in and around Center City and University City, where demand is also highest. Outlying neighborhoods such as South Philly, West Parkside, and Northeast Philly show lower errors because demand is lower and more stable.\n\n## Temporal Error Patterns\n\nWhen are we most wrong?\n\n```{r temporal_errors}\n# MAE by time of day and day type\ntemporal_errors <- test %>%\n  group_by(time_of_day, weekend) %>%\n  summarize(\n    MAE = mean(abs_error, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  mutate(day_type = ifelse(weekend == 1, \"Weekend\", \"Weekday\"))\n\nggplot(temporal_errors, aes(x = time_of_day, y = MAE, fill = day_type)) +\n  geom_col(position = \"dodge\") +\n  scale_fill_manual(values = c(\"Weekday\" = \"#08519c\", \"Weekend\" = \"#6baed6\")) +\n  labs(\n    title = \"Prediction Errors by Time Period\",\n    subtitle = \"When is the model struggling most?\",\n    x = \"Time of Day\",\n    y = \"Mean Absolute Error (trips)\",\n    fill = \"Day Type\"\n  ) +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\nThe model performs best during the overnight and evening hours, when demand is low and stable. Errors increase during the middle of the day and are highest during the AM and PM rush periods, especially the PM commute. This makes sense because rush-hour ridership is far more volatile and sensitive to small changes in weather, work schedules, and travel patterns.\n\n## Errors and Demographics\n\nAre prediction errors related to neighborhood characteristics?\n\n```{r errors_demographics}\n# Join demographic data to station errors\nstation_errors_demo <- station_errors %>%\n  left_join(\n    station_attributes %>% select(start_station, Med_Inc, Percent_Taking_Transit, Percent_White),\n    by = \"start_station\"\n  ) %>%\n  filter(!is.na(Med_Inc))\n\n# Create plots\np1 <- ggplot(station_errors_demo, aes(x = Med_Inc, y = MAE)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  scale_x_continuous(labels = scales::dollar) +\n  labs(title = \"Errors vs. Median Income\", x = \"Median Income\", y = \"MAE\") +\n  plotTheme\n\np2 <- ggplot(station_errors_demo, aes(x = Percent_Taking_Transit, y = MAE)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(title = \"Errors vs. Transit Usage\", x = \"% Taking Transit\", y = \"MAE\") +\n  plotTheme\n\np3 <- ggplot(station_errors_demo, aes(x = Percent_White, y = MAE)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(title = \"Errors vs. Race\", x = \"% White\", y = \"MAE\") +\n  plotTheme\n\ngrid.arrange(p1, p2, p3, ncol = 2)\n```\n\n**Critical Question:** Are prediction errors systematically higher in certain demographic groups? What are the equity implications?\n\nAcross Philadelphia, prediction errors show meaningful relationships with neighborhood demographics. Errors tend to be slightly higher in stations located in higher-income or higher-percentage-White areas, suggesting the model struggles more in wealthier, less transit-dependent neighborhoods where trip patterns may be more irregular. In contrast, stations in areas with higher transit use show lower errors, likely because these neighborhoods have more stable, predictable travel demand. These patterns raise equity considerations: if models systematically underperform in certain demographic groups, operational decisions (like rebalancing) could unintentionally favor or disadvantage specific communities.\n\n------------------------------------------------------------------------\n\n# Part 2: COMPARE RESULTS BETWEEN Q1 2025 AND Q2 2024\n\n## Compare MAE Across Quarters\n\n```{r compare_mae_q1_q2}\nmae_results_q2 <- mae_results %>%\n  mutate(Quarter = \"Q2 2024\")\n\nmae_results_q1_labeled <- mae_results_q1 %>%\n  mutate(Quarter = \"Q1 2025\")\n\nmae_compare <- bind_rows(mae_results_q2, mae_results_q1_labeled)\n\nkable(mae_compare,\n      digits = 2,\n      caption = \"Model MAE Comparison: Q1 2025 vs Q2 2024\",\n      col.names = c(\"Model\", \"MAE (trips)\", \"Quarter\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\",\"hover\"))\n```\n\n## MAE Comparison Plot\n\n```{r compare_mae_plot_q1_q2}\nggplot(mae_compare,\n       aes(x = Model, y = MAE, fill = Quarter)) +\n  geom_col(position = \"dodge\") +\n  geom_text(aes(label = round(MAE, 2)),\n            position = position_dodge(width = 0.9),\n            vjust = -0.4, size = 3) +\n  labs(\n    title = \"Model Performance Across Quarters\",\n    y     = \"Mean Absolute Error (trips)\",\n    x     = \"Model\"\n  ) +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\nModels consistently perform better in Q1 2025 than in Q2 2024, with lower MAE across every specification. Winter travel is more predictable because most trips are work-related and follow a routine. In Q2 2024, ridership is higher and more random due to nicer weather, outdoor activities, and tourism, which makes predictions harder. This is why every model has lower MAE in Q1 than Q2.\n\n## Temporal Error Comparison: Q1 vs Q2\n\n```{r compare_temporal_errors_q1_q2}\n\n#Q1 2025 TEMPORAL ERRORS\ntemporal_errors_q1 <- test_q1 %>%\n  group_by(time_of_day_q1, weekend) %>%\n  summarize(\n    MAE = mean(abs_error_q1, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  mutate(\n    Day_Type = ifelse(weekend == 1, \"Weekend\", \"Weekday\"),\n    Quarter = \"Q1 2025\",\n    Time_of_Day = time_of_day_q1\n  ) %>%\n  select(Time_of_Day, MAE, Day_Type, Quarter)\n\n\n#Q2 2024 TEMPORAL ERRORS\ntemporal_errors_q2 <- test %>%        # your Q2 dataset\n  group_by(time_of_day, weekend) %>%\n  summarize(\n    MAE = mean(abs_error, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  mutate(\n    Day_Type = ifelse(weekend == 1, \"Weekend\", \"Weekday\"),\n    Quarter = \"Q2 2024\",\n    Time_of_Day = time_of_day\n  ) %>%\n  select(Time_of_Day, MAE, Day_Type, Quarter)\n\n\n#COMBINE\ntemporal_compare <- bind_rows(temporal_errors_q1, temporal_errors_q2)\n\n\n#PLOT\nggplot(temporal_compare,\n       aes(x = Time_of_Day, y = MAE, fill = Day_Type)) +\n  geom_col(position = \"dodge\") +\n  facet_wrap(~ Quarter, ncol = 2) +\n  labs(\n    title = \"Prediction Errors by Time of Day and Quarter\",\n    y = \"Mean Absolute Error (trips)\",\n    x = \"Time of Day\",\n    fill = \"Day Type\"\n  ) +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\nQ1 and Q2 have different error patterns. In Q1 2025, errors spike during morning and evening rush hours, when travel is busiest and most unpredictable. Overnight and evening hours are easiest to predict. In Q2 2024, errors are more evenly spread throughout the day because people ride more for leisure, not just commuting. Seasonal differences, like winter vs. spring, explain most of the pattern.\n\n## Feature Importance Comparison\n\n```{r compare_feature_importance_q1_q2}\nget_coef_table <- function(model, quarter_label) {\n  sm <- summary(model)$coefficients\n  tibble(\n    Variable  = rownames(sm),\n    Estimate  = sm[, 1]\n  ) %>%\n    mutate(\n      Quarter  = quarter_label,\n      Abs_Est  = abs(Estimate)\n    )\n}\n\ncoefs_q2 <- get_coef_table(model2,   \"Q2 2024\")\ncoefs_q1 <- get_coef_table(model2_q1,\"Q1 2025\")\n\nvars_focus <- c(\"Temperature\", \"Precipitation\",\n                \"lag1Hour\", \"lag3Hours\", \"lag1day\")\n\nfeature_compare <- bind_rows(coefs_q2, coefs_q1) %>%\n  filter(Variable %in% vars_focus) %>%\n  arrange(Quarter, desc(Abs_Est))\n\nkable(feature_compare,\n      digits = 3,\n      caption = \"Key Coefficient Magnitudes in Model 2 by Quarter\") %>%\n  kable_styling(bootstrap_options = c(\"striped\",\"hover\"))\n```\n\nDifferent features matter in each quarter. In Q1 2025, precipitation is the strongest predictor because winter weather sharply affects ridership. Temporal lags also matter because demand is more consistent hour to hour. In Q2 2024, lag effects are still important, but weather has a smaller impact, and trips follow more flexible patterns. Overall, winter demand depends more on weather, while spring demand depends more on regular daily patterns.\n\n------------------------------------------------------------------------\n\n# Part 3: FEATURE ENGINEERING AND MODEL IMPROVEMENT\n\n```{r feature_engineering}\nstudy_panel_complete_fe <- study_panel_complete %>%\narrange(start_station, interval60) %>%\ngroup_by(start_station) %>%\nmutate(\ncenter_city = if_else(\nstart_lon.x >= -75.18 & start_lon.x <= -75.13 &\nstart_lat.x >= 39.94 & start_lat.x <= 39.96,\n1, 0, missing = 0\n),\nrush_demand = rush_hour * Trip_Count,\nlag1week = lag(Trip_Count, 24 * 7),\nroll7day = rollmean(Trip_Count, k = 24 * 7,\nalign = \"right\", fill = NA)\n) %>%\nungroup() %>%\nmutate(\nrush_demand = replace_na(rush_demand, 0),\nlag1week = replace_na(lag1week, 0),\nroll7day = replace_na(roll7day, 0)\n)\n\n#Match train/test splits using the same rows as original objects\n\ntrain_fe <- study_panel_complete_fe %>%\nsemi_join(train %>% select(interval60, start_station),\nby = c(\"interval60\", \"start_station\"))\n\ntest_fe <- study_panel_complete_fe %>%\nsemi_join(test %>% select(interval60, start_station),\nby = c(\"interval60\", \"start_station\"))\n```\n\n# Build Improved Model (Model 2 with New Features)\n\n```{r improved_model}\nmodel2_fe <- lm(\nTrip_Count ~\nas.factor(hour) + dotw +\nTemperature + Precipitation +\nlag1Hour + lag3Hours + lag1day +\ncenter_city + rush_demand +\nlag1week + roll7day,\ndata = train_fe\n)\n```\n\n# Predict on test\n\n```{r predict_on_test}\ntest_fe <- test_fe %>%\nmutate(pred_fe = predict(model2_fe, newdata = .))\n```\n\n#MAE Comparison Old vs New model 2\n\n```{r mae_oldvsnew}\nmae_old <- mean(abs(test$Trip_Count - test$pred2), na.rm = TRUE)\nmae_new <- mean(abs(test_fe$Trip_Count - test_fe$pred_fe), na.rm = TRUE)\n\nmae_compare_fe <- tibble(\nModel = c(\"Original Model 2\", \"Improved Model 2 + New Features\"),\nMAE = c(mae_old, mae_new)\n)\n\nkable(mae_compare_fe,\ncaption = \"MAE Comparison: Original vs Improved Model\") %>%\nkable_styling(bootstrap_options = c(\"striped\",\"hover\"))\n```\n\n#Plot\n\n```{r plot_new}\nggplot(mae_compare_fe, aes(x = Model, y = MAE, fill = Model)) +\ngeom_col() +\ngeom_text(aes(label = round(MAE, 3)), vjust = -0.5) +\nlabs(\ntitle = \"Model Improvement After Feature Engineering\",\ny = \"MAE (trips)\"\n) +\nplotTheme +\ntheme(legend.position = \"none\")\n```\n\nModel 2 already included the main predictors like hour of day, day of week, weather, and a few short-term lags. But after looking at the error analysis, it was pretty clear that the model was still missing some important patterns. So I added four new features that directly targeted the biggest problems I found.\n\nThe first feature I added was a Center City indicator, because the error maps showed the model was consistently under-predicting in the downtown stations. These stations have way more activity than the rest of the city, so giving the model a simple 0/1 flag helps it separate the normal stations from the very busy ones.\n\nNext, I added rush_demand, which is rush hour × recent demand. The temporal plots showed that most of the big mistakes happened during the morning and evening commute times. This feature tells the model when a station’s demand tends to spike specifically during rush hour, which helps reduce under-prediction during those busy periods.\n\nI also added lag1week, which is the same hour from the previous week. The data showed strong weekly patterns. The original model only looked back a few hours or one day, so adding this weekly lag helps the model pick up those repeating patterns.\n\nAnd last, I added roll7day, the 7-day rolling average. Hour-to-hour demand can be really noisy, so this gives the model a smoother signal showing whether demand at a station has been trending up or down over the last week. This helps make predictions more stable instead of jumping around from one random spike.\n\nTogether, these four features directly address the main issues found in the error analysis and help the model make more consistent and accurate predictions.\n\n------------------------------------------------------------------------\n\n## Part 4: Critical Reflection\n\n1.  **Operational implications:** Even though my improved model has a fairly low MAE, it still isn’t perfect, and Indego would need to be careful about relying on it. Most of the time, an MAE under 1 trip is “good enough” to guide rebalancing decisions, but errors during rush hour or at busy downtown stations can still cause real problems. A station emptying out 2–3 bikes earlier than expected can affect commuters pretty quickly. So I would recommend using this model as a supportive tool rather than something that fully automates rebalancing. It works best for planning ahead and spotting likely hotspots, but staff should still monitor real-time conditions, weather, and special events.\n\n2.  **Equity considerations:** My error analysis showed that prediction accuracy wasn’t equal across all neighborhoods. Some areas, like Center City and higher-income stations had larger error, which means the model could unintentionally over or under serve certain parts of the city. If Indego relied on these predictions without oversight, it could reinforce existing inequalities in bike access by sending more rebalancing resources to already advantaged areas.\n\n3.  **Model limitations:** The model doesn’t account for special events, tourism spikes, construction, transit delays, or sudden weather changes, all of which can dramatically change bike demand. It also assumes past patterns repeat in the same way every week, which isn’t always true. If I could add more features, I would add real-time weather forecasts, event calendars, and bike lane accessibility.\n\n------------------------------------------------------------------------\n","srcMarkdownNoYaml":"\n\n```{r}\n#| echo: false\nknitr::opts_chunk$set(\n  echo = TRUE,\n  warning = FALSE,\n  message = FALSE,\n  cache = TRUE\n)\n```\n\n# Introduction\n\n## The Rebalancing Challenge in Philadelphia\n\nPhiladelphia's Indego bike share system faces the same operational challenge as every bike share system: **rebalancing bikes to meet anticipated demand**.\n\nImagine you're an Indego operations manager at 6:00 AM on a Monday morning. You have: - 200 stations across Philadelphia - Limited trucks and staff for moving bikes - 2-3 hours before morning rush hour demand peaks - **The question:** Which stations will run out of bikes by 8:30 AM?\n\nThis lab will teach you to build predictive models that forecast bike share demand across **space** (different stations) and **time** (different hours) to help solve this operational problem.\n\n------------------------------------------------------------------------\n\n```{r}\n#| echo: false\n# Core tidyverse\nlibrary(tidyverse)\nlibrary(lubridate)\n\n# Spatial data\nlibrary(sf)\nlibrary(tigris)\n\n# Census data\nlibrary(tidycensus)\n\n# Weather data\nlibrary(riem)  # For Philadelphia weather from ASOS stations\n\n\n# Visualization\nlibrary(viridis)\nlibrary(gridExtra)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(zoo)\n\n# here!\nlibrary(here)\n# Get rid of scientific notation. We gotta look good!\noptions(scipen = 999)\n```\n\n```{r}\n#| echo: false\nplotTheme <- theme(\n  plot.title = element_text(size = 14, face = \"bold\"),\n  plot.subtitle = element_text(size = 10),\n  plot.caption = element_text(size = 8),\n  axis.text.x = element_text(size = 10, angle = 45, hjust = 1),\n  axis.text.y = element_text(size = 10),\n  axis.title = element_text(size = 11, face = \"bold\"),\n  panel.background = element_blank(),\n  panel.grid.major = element_line(colour = \"#D0D0D0\", size = 0.2),\n  panel.grid.minor = element_blank(),\n  axis.ticks = element_blank(),\n  legend.position = \"right\"\n)\n\nmapTheme <- theme(\n  plot.title = element_text(size = 14, face = \"bold\"),\n  plot.subtitle = element_text(size = 10),\n  plot.caption = element_text(size = 8),\n  axis.line = element_blank(),\n  axis.text = element_blank(),\n  axis.ticks = element_blank(),\n  axis.title = element_blank(),\n  panel.background = element_blank(),\n  panel.border = element_blank(),\n  panel.grid.major = element_line(colour = 'transparent'),\n  panel.grid.minor = element_blank(),\n  legend.position = \"right\",\n  plot.margin = margin(1, 1, 1, 1, 'cm'),\n  legend.key.height = unit(1, \"cm\"),\n  legend.key.width = unit(0.2, \"cm\")\n)\n\npalette5 <- c(\"#eff3ff\", \"#bdd7e7\", \"#6baed6\", \"#3182bd\", \"#08519c\")\n```\n\n# Data Import & Preparation\n\n## Load Indego Trip Data (Q1 2025)\n\n```{r}\n#| echo: false\n#| message: false \n#| output: false\n\n# Read Q1 2025 data\nindego_q1 <- read_csv(\n  here(\"C:/Users/chloe.robinson/Desktop/PENN/FALL 2025/Public Policy Analytics/Week 1/portfolio-setup-chloelr/Labs/Lab 5/Data/indego-trips-2025-q1.csv\")\n)\n\n# Quick look at the data\nglimpse(indego_q1)\n```\n\n```{r}\n#| echo: false\n#| results: hide\n#| message: false\n#| warning: false\n\n# How many trips?\ncat(\"Total trips in Q1 2025:\", nrow(indego_q1), \"\\n\")\n\n# Date range\ncat(\"Date range:\",\n    min(mdy_hm(indego_q1$start_time)), \"to\",\n    max(mdy_hm(indego_q1$start_time)), \"\\n\")\n\n# How many unique stations?\ncat(\"Unique start stations:\", length(unique(indego_q1$start_station)), \"\\n\")\n\n# Trip types\ntable(indego_q1$trip_route_category)\n\n# Passholder types\ntable(indego_q1$passholder_type)\n\n# Bike types\ntable(indego_q1$bike_type)\n```\n\n```{r summary_table_q1}\n#| echo: false\n#| message: false\n#| warning: false\n\nsummary_table_q1 <- tibble(\n  `Total Trips`           = nrow(indego_q1),\n  `Date Range Start`      = min(mdy_hm(indego_q1$start_time)),\n  `Date Range End`        = max(mdy_hm(indego_q1$start_time)),\n  `Unique Start Stations` = length(unique(indego_q1$start_station))\n)\n\nkable(summary_table_q1, caption = \"Summary of Indego Trip Data – Q1 2025\") |>\n  kable_styling(latex_options = \"hold_position\")\n```\n\n## Create Time Bins (Q1 2025)\n\n```{r}\nindego_q1 <- indego_q1 %>%\n  mutate(\n    # Parse datetime\n    start_datetime = mdy_hm(start_time),\n    end_datetime   = mdy_hm(end_time),\n\n    # Create hourly bins\n    interval60 = floor_date(start_datetime, unit = \"hour\"),\n\n    # Extract time features\n    week  = week(interval60),\n    month = month(interval60, label = TRUE),\n    dotw  = wday(interval60, label = TRUE),\n    hour  = hour(interval60),\n    date  = as.Date(interval60),\n\n    # Create useful indicators\n    weekend   = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n```\n\n```{r}\n#| echo: false\n\nindego_q1 %>%\n  select(start_datetime, interval60, week, dotw, hour, weekend) %>%\n  head(10) %>%\n  kable(caption = \"Preview of temporal features – Q1 2025\") %>%\n  kable_styling(latex_options = c(\"striped\", \"hold_position\"))\n```\n\n# Exploratory Analysis Q1 2025\n\n## Trips Over Time (Q1 2025)\n\n```{r}\n# Daily trip counts\ndaily_trips_q1 <- indego_q1 %>%\n  group_by(date) %>%\n  summarize(trips = n())\n\nggplot(daily_trips_q1, aes(x = date, y = trips)) +\n  geom_line(color = \"#3182bd\", linewidth = 1) +\n  geom_smooth(se = FALSE, color = \"red\", linetype = \"dashed\") +\n  labs(\n    title = \"Indego Daily Ridership – Q1 2025\",\n    subtitle = \"Winter ridership patterns in Philadelphia\",\n    x = \"Date\",\n    y = \"Daily Trips\",\n    caption = \"Source: Indego bike share\"\n  ) +\n  plotTheme\n```\n\n## Hourly Patterns (Q1 2025)\n\n```{r}\nhourly_patterns_q1 <- indego_q1 %>%\n  group_by(hour, weekend) %>%\n  summarize(avg_trips = n() / n_distinct(date)) %>%\n  mutate(day_type = ifelse(weekend == 1, \"Weekend\", \"Weekday\"))\n\nggplot(hourly_patterns_q1, aes(x = hour, y = avg_trips, color = day_type)) +\n  geom_line(linewidth = 1.2) +\n  scale_color_manual(values = c(\"Weekday\" = \"#08519c\", \"Weekend\" = \"#6baed6\")) +\n  labs(\n    title = \"Average Hourly Ridership Patterns – Q1 2025\",\n    subtitle = \"Weekday commute peaks vs. weekend leisure patterns\",\n    x = \"Hour of Day\",\n    y = \"Average Trips per Hour\",\n    color = \"Day Type\"\n  ) +\n  plotTheme\n```\n\n## Top Stations (Q1 2025)\n\n```{r}\ntop_stations_q1 <- indego_q1 %>%\n  count(start_station, start_lat, start_lon, name = \"trips\") %>%\n  arrange(desc(trips)) %>%\n  head(10)\n```\n\n```{r}\n#| echo: false\n\nkable(top_stations_q1,\n      caption = \"Top 10 Indego Stations by Trip Origins – Q1 2025\",\n      format.args = list(big.mark = \",\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n# Get Philadelphia Spatial Context (Q1 2025)\n\n## Load Philadelphia Census Data(Q1 2025)\n\n```{r load_census_q1}\n#| echo: false\n#| results: hide\n#| message: false\n#| warning: false\n\nphilly_census_q1 <- get_acs(\n  geography = \"tract\",\n  variables = c(\n    \"B01003_001\",\n    \"B19013_001\",\n    \"B08301_001\",\n    \"B08301_010\",\n    \"B02001_002\",\n    \"B25077_001\"\n  ),\n  state = \"PA\",\n  county = \"Philadelphia\",\n  year = 2022,\n  geometry = TRUE,\n  output = \"wide\"\n) %>%\n  rename(\n    Total_Pop = B01003_001E,\n    Med_Inc = B19013_001E,\n    Total_Commuters = B08301_001E,\n    Transit_Commuters = B08301_010E,\n    White_Pop = B02001_002E,\n    Med_Home_Value = B25077_001E\n  ) %>%\n  mutate(\n    Percent_Taking_Transit = (Transit_Commuters / Total_Commuters) * 100,\n    Percent_White = (White_Pop / Total_Pop) * 100\n  ) %>%\n  st_transform(crs = 4326)\n\nglimpse(philly_census_q1)\n```\n\n## Map Philadelphia Context (Q1 2025)\n\n```{r map_philly_q1}\nggplot() +\n  geom_sf(data = philly_census_q1, aes(fill = Med_Inc), color = NA) +\n  scale_fill_viridis(\n    option = \"viridis\",\n    name = \"Median\\nIncome\",\n    labels = scales::dollar\n  ) +\n  labs(\n    title = \"Philadelphia Median Household Income by Census Tract (Q1 2025)\",\n    subtitle = \"Context for bike share demand\"\n  ) +\n  geom_point(\n    data = indego_q1,\n    aes(x = start_lon, y = start_lat),\n    color = \"red\", size = 0.25, alpha = 0.6\n  ) +\n  mapTheme\n```\n\n## Join Census Data to Stations\n\n```{r join_census_to_stations_q1}\nstations_sf_q1 <- indego_q1 %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  st_as_sf(coords = c(\"start_lon\", \"start_lat\"), crs = 4326)\n\nstations_census_q1 <- st_join(stations_sf_q1, philly_census_q1, left = TRUE) %>%\n  st_drop_geometry()\n\nstations_for_map_q1 <- indego_q1 %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  left_join(\n    stations_census_q1 %>% select(start_station, Med_Inc),\n    by = \"start_station\"\n  ) %>%\n  mutate(has_census = !is.na(Med_Inc))\n\nindego_census_q1 <- indego_q1 %>%\n  left_join(\n    stations_census_q1 %>% \n      select(start_station, Med_Inc, Percent_Taking_Transit, Percent_White, Total_Pop),\n      by = \"start_station\"\n  )\n```\n\n```{r join_census_to_stations2_q1}\n#| echo: false\nstations_for_map_q1 <- indego_q1 %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  left_join(\n    stations_census_q1 %>% select(start_station, Med_Inc),\n    by = \"start_station\"\n  ) %>%\n  mutate(has_census = !is.na(Med_Inc))\n\nggplot() +\n  geom_sf(data = philly_census_q1, aes(fill = Med_Inc), color = \"white\", size = 0.1) +\n  scale_fill_viridis(\n    option = \"viridis\",\n    name = \"Median\\nIncome\",\n    labels = scales::dollar,\n    na.value = \"grey90\"\n  ) +\n  geom_point(\n    data = stations_for_map_q1 %>% filter(has_census),\n    aes(x = start_lon, y = start_lat),\n    color = \"grey30\", size = 1, alpha = 0.6\n  ) +\n  geom_point(\n    data = stations_for_map_q1 %>% filter(!has_census),\n    aes(x = start_lon, y = start_lat),\n    color = \"red\", size = 1, shape = 4, stroke = 1.5\n  ) +\n  labs(\n    title = \"Philadelphia Median Household Income (Q1 2025)\",\n    subtitle = \"RED = stations without census match\",\n    caption = \"Non-residential or outside-tract stations\"\n  ) +\n  mapTheme\n```\n\n```{r}\nvalid_stations_q1 <- stations_census_q1 %>%\n  filter(!is.na(Med_Inc)) %>%\n  pull(start_station)\n\nindego_census_q1 <- indego_q1 %>%\n  filter(start_station %in% valid_stations_q1) %>%\n  left_join(\n    stations_census_q1 %>% \n      select(start_station, Med_Inc, Percent_Taking_Transit, \n             Percent_White, Total_Pop),\n    by = \"start_station\"\n  )\n```\n\n# Dealing with missing data (Q1 2025)\n\n## Get Weather Data (Q1 2025)\n\n```{r get_weather_q1}\nweather_data_q1 <- riem_measures(\n  station    = \"PHL\",\n  date_start = \"2025-01-01\",\n  date_end   = \"2025-03-31\"\n)\n\nweather_processed_q1 <- weather_data_q1 %>%\n  mutate(\n    interval60    = floor_date(valid, unit = \"hour\"),\n    Temperature   = tmpf,\n    Precipitation = ifelse(is.na(p01i), 0, p01i),\n    Wind_Speed    = sknt\n  ) %>%\n  select(interval60, Temperature, Precipitation, Wind_Speed) %>%\n  distinct()\n\nweather_complete_q1 <- weather_processed_q1 %>%\n  complete(interval60 = seq(min(interval60), max(interval60), by = \"hour\")) %>%\n  fill(Temperature, Precipitation, Wind_Speed, .direction = \"down\")\n```\n\n## Visualize Weather Patterns (Q1 2025)\n\n```{r visualize_weather_q1}\nggplot(weather_complete_q1, aes(x = interval60, y = Temperature)) +\n  geom_line(color = \"#3182bd\", alpha = 0.7) +\n  geom_smooth(se = FALSE, color = \"red\") +\n  labs(\n    title = \"Philadelphia Temperature – Q1 2025\",\n    subtitle = \"Winter conditions\",\n    x = \"Date\",\n    y = \"Temperature (°F)\"\n  ) +\n  plotTheme\n```\n\n# Create Space-TIme Panel\n\n## Aggregate Trips to Station-Hour Level (Q1 2025)\n\n```{r aggregate_trips_q1}\ntrips_panel_q1 <- indego_census_q1 %>%\n  group_by(interval60, start_station, start_lat, start_lon,\n           Med_Inc, Percent_Taking_Transit, Percent_White, Total_Pop) %>%\n  summarize(Trip_Count = n()) %>%\n  ungroup()\n```\n\n## Create Complete Panel Structure (Q1 2025)\n\n```{r complete_panel_q1}\nn_stations_q1 <- length(unique(trips_panel_q1$start_station))\nn_hours_q1    <- length(unique(trips_panel_q1$interval60))\nexpected_rows_q1 <- n_stations_q1 * n_hours_q1\n\nstudy_panel_q1 <- expand.grid(\n  interval60   = unique(trips_panel_q1$interval60),\n  start_station = unique(trips_panel_q1$start_station)\n) %>%\n  left_join(trips_panel_q1, by = c(\"interval60\", \"start_station\")) %>%\n  mutate(Trip_Count = replace_na(Trip_Count, 0))\n\nstation_attributes_q1 <- trips_panel_q1 %>%\n  group_by(start_station) %>%\n  summarize(\n    start_lat = first(start_lat),\n    start_lon = first(start_lon),\n    Med_Inc   = first(Med_Inc),\n    Percent_Taking_Transit = first(Percent_Taking_Transit),\n    Percent_White = first(Percent_White),\n    Total_Pop = first(Total_Pop)\n  )\n\nstudy_panel_q1 <- study_panel_q1 %>%\n  left_join(station_attributes_q1, by = \"start_station\")\n```\n\n## Add Time Features (Q1 2025)\n\n```{r add_time_features_q1}\nstudy_panel_q1 <- study_panel_q1 %>%\n  mutate(\n    week     = week(interval60),\n    month    = month(interval60, label = TRUE),\n    dotw     = wday(interval60, label = TRUE),\n    hour     = hour(interval60),\n    date     = as.Date(interval60),\n    weekend  = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n```\n\n## Join Weather Data (Q1 2025)\n\n```{r join_weather_q1}\nstudy_panel_q1 <- study_panel_q1 %>%\n  left_join(weather_complete_q1, by = \"interval60\")\n```\n\n#Create Temporal Lag Variables (Q1 2025)\n\n```{r create_lags_q1}\nstudy_panel_q1 <- study_panel_q1 %>%\n  arrange(start_station, interval60)\n\nstudy_panel_q1 <- study_panel_q1 %>%\n  group_by(start_station) %>%\n  mutate(\n    lag1Hour   = lag(Trip_Count, 1),\n    lag2Hours  = lag(Trip_Count, 2),\n    lag3Hours  = lag(Trip_Count, 3),\n    lag12Hours = lag(Trip_Count, 12),\n    lag1day    = lag(Trip_Count, 24)\n  ) %>%\n  ungroup()\n\nstudy_panel_complete_q1 <- study_panel_q1 %>%\n  filter(!is.na(lag1day))\n\nstudy_panel_complete_q1 <- study_panel_complete_q1 %>%\n  mutate(\n    month = factor(month, levels = c(\"Jan\", \"Feb\", \"Mar\")),\n    dotw  = factor(dotw,  levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"))\n  )\n```\n\n```{r lag_correlations_q1}\nexample_station_q1 <- study_panel_complete_q1 %>%\n  filter(start_station == first(start_station)) %>%\n  head(168)\n\nggplot(example_station_q1, aes(x = interval60)) +\n  geom_line(aes(y = Trip_Count, color = \"Current\"), linewidth = 1) +\n  geom_line(aes(y = lag1Hour, color = \"1 Hour Ago\"), linewidth = 1, alpha = 0.7) +\n  geom_line(aes(y = lag1day, color = \"24 Hours Ago\"), linewidth = 1, alpha = 0.7) +\n  scale_color_manual(values = c(\n    \"Current\"     = \"#08519c\",\n    \"1 Hour Ago\"  = \"#3182bd\",\n    \"24 Hours Ago\"= \"#6baed6\"\n  )) +\n  labs(\n    title  = \"Temporal Lag Patterns at One Station – Q1 2025\",\n    x      = \"Date-Time\",\n    y      = \"Trip Count\",\n    color  = \"Time Period\"\n  ) +\n  plotTheme\n```\n\n## Temporal Train/Test Split (Q1 2025)\n\n```{r temporal_split_q1}\ntrain_weeks_q1 <- 1:9\ntest_weeks_q1  <- 10:13\n\nearly_stations_q1 <- study_panel_complete_q1 %>%\n  filter(week %in% train_weeks_q1, Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\nlate_stations_q1 <- study_panel_complete_q1 %>%\n  filter(week %in% test_weeks_q1, Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\ncommon_stations_q1 <- intersect(early_stations_q1, late_stations_q1)\n\nstudy_panel_q1_ts <- study_panel_complete_q1 %>%\n  filter(start_station %in% common_stations_q1)\n\ntrain_q1 <- study_panel_q1_ts %>%\n  filter(week %in% train_weeks_q1)\n\ntest_q1 <- study_panel_q1_ts %>%\n  filter(week %in% test_weeks_q1)\n```\n\n```{r summary_train_test_q1}\n#| echo: false\n\nsummary_table_q1_ts <- tibble(\n  Set = c(\"Training (Q1 2025)\", \"Testing (Q1 2025)\"),\n  Observations = c(nrow(train_q1), nrow(test_q1)),\n  Date_Range = c(\n    paste(min(train_q1$date), \"to\", max(train_q1$date)),\n    paste(min(test_q1$date), \"to\", max(test_q1$date))\n  )\n)\n\nkable(summary_table_q1_ts,\n      caption = \"Train/Test Summary – Q1 2025\") %>%\n  kable_styling(latex_options = c(\"striped\", \"hold_position\"))\n```\n\n# Build Predictive Models\n\n## Model 1: Baseline (Time + Weather) — Q1 2025\n\n```{r model1_q1}\ntrain_q1 <- train_q1 %>%\n  mutate(dotw_simple = factor(dotw, \n                              levels = c(\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Fri\",\"Sat\",\"Sun\")))\n\ncontrasts(train_q1$dotw_simple) <- contr.treatment(7)\n\nmodel1_q1 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple +\n    Temperature + Precipitation,\n  data = train_q1\n)\n```\n\n## Model 2: Add Temporal Lags — Q1 2025\n\n```{r model2_q1}\nmodel2_q1 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple +\n    Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day,\n  data = train_q1\n)\n```\n\n## Model 3: Add Demographics — Q1 2025\n\n```{r model3_q1}\nmodel3_q1 <- lm(\n  Trip_Count ~ \n    as.factor(hour) +\n    dotw_simple +\n    Temperature +\n    Precipitation +\n    lag1Hour +\n    lag3Hours +\n    lag1day +\n    Med_Inc.x +\n    Percent_Taking_Transit.x +\n    Percent_White.x,\n  data = train_q1\n)\n```\n\n## Model 4: Add Station Fixed Effects — Q1 2025\n\n```{r model4_q1}\nmodel4_q1 <- lm(\n  Trip_Count ~ \n    as.factor(hour) +\n    dotw_simple +\n    Temperature +\n    Precipitation +\n    lag1Hour +\n    lag3Hours +\n    lag1day +\n    Med_Inc.x +\n    Percent_Taking_Transit.x +\n    Percent_White.x +\n    as.factor(start_station),\n  data = train_q1\n)\n```\n\n## Model 5: Add Rush Hour Interaction — Q1 2025\n\n```{r model5_q1}\ntrain_q1$month <- factor(train_q1$month, levels = c(\"Jan\",\"Feb\",\"Mar\"))\ntest_q1$month  <- factor(test_q1$month, levels = levels(train_q1$month))\n\nmodel5_q1 <- lm(\n  Trip_Count ~ \n    as.factor(hour) +\n    dotw_simple +\n    Temperature +\n    Precipitation +\n    lag1Hour +\n    lag3Hours +\n    lag1day +\n    rush_hour +\n    month +\n    Med_Inc.x +\n    Percent_Taking_Transit.x +\n    Percent_White.x +\n    as.factor(start_station) +\n    rush_hour * weekend,\n  data = train_q1\n)\n```\n\n# Model Evaluation\n\n## Calculate Predictions and MAE — Q1 2025\n\n```{r calculate_mae_q1}\ntest_q1$month <- factor(test_q1$month, levels = model5_q1$xlevels$month)\n\ntest_q1 <- test_q1 %>%\n  mutate(dotw_simple = factor(dotw,\n                              levels = c(\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Fri\",\"Sat\",\"Sun\")))\n\ncontrasts(test_q1$dotw_simple) <- contr.treatment(7)\n\ntest_q1 <- test_q1 %>%\n  mutate(\n    pred1_q1 = predict(model1_q1, newdata = test_q1),\n    pred2_q1 = predict(model2_q1, newdata = test_q1),\n    pred3_q1 = predict(model3_q1, newdata = test_q1),\n    pred4_q1 = predict(model4_q1, newdata = test_q1),\n    pred5_q1 = predict(model5_q1, newdata = test_q1)\n  )\n\nmae_results_q1 <- tibble(\n  Model = c(\n    \"1. Time + Weather\",\n    \"2. + Temporal Lags\",\n    \"3. + Demographics\",\n    \"4. + Station FE\",\n    \"5. + Rush Hour Interaction\"\n  ),\n  MAE = c(\n    mean(abs(test_q1$Trip_Count - test_q1$pred1_q1), na.rm = TRUE),\n    mean(abs(test_q1$Trip_Count - test_q1$pred2_q1), na.rm = TRUE),\n    mean(abs(test_q1$Trip_Count - test_q1$pred3_q1), na.rm = TRUE),\n    mean(abs(test_q1$Trip_Count - test_q1$pred4_q1), na.rm = TRUE),\n    mean(abs(test_q1$Trip_Count - test_q1$pred5_q1), na.rm = TRUE)\n  )\n)\n\nkable(mae_results_q1,\n      digits = 2,\n      caption = \"Mean Absolute Error by Model (Q1 2025 Test Set)\",\n      col.names = c(\"Model\", \"MAE (trips)\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\",\"hover\"))\n```\n\n## Visualize Model Comparison — Q1 2025\n\n```{r compare_models_q1}\nggplot(mae_results_q1, aes(x = reorder(Model, -MAE), y = MAE)) +\n  geom_col(fill = \"#3182bd\", alpha = 0.8) +\n  geom_text(aes(label = round(MAE, 2)), vjust = -0.5) +\n  labs(\n    title = \"Model Performance Comparison — Q1 2025\",\n    subtitle = \"Lower MAE = Better Predictions\",\n    x = \"Model\",\n    y = \"Mean Absolute Error (trips)\"\n  ) +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n# Space- Time Error Analysis\n\n## Observed vs. Predicted — Q1 2025 (Using Model 2)\n\n```{r obs_vs_pred_q1}\ntest_q1 <- test_q1 %>%\n  mutate(\n    error_q1     = Trip_Count - pred2_q1,\n    abs_error_q1 = abs(error_q1),\n    time_of_day_q1 = case_when(\n      hour < 7                  ~ \"Overnight\",\n      hour >= 7 & hour < 10     ~ \"AM Rush\",\n      hour >= 10 & hour < 15    ~ \"Mid-Day\",\n      hour >= 15 & hour <= 18   ~ \"PM Rush\",\n      hour > 18                 ~ \"Evening\"\n    )\n  )\n\nggplot(test_q1, aes(x = Trip_Count, y = pred2_q1)) +\n  geom_point(alpha = 0.2, color = \"#3182bd\") +\n  geom_abline(slope = 1, intercept = 0, color = \"red\", linewidth = 1) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"darkgreen\") +\n  facet_grid(weekend ~ time_of_day_q1) +\n  labs(\n    title = \"Observed vs. Predicted Trips — Q1 2025\",\n    x = \"Observed Trips\",\n    y = \"Predicted Trips\"\n  ) +\n  plotTheme\n```\n\n##Spatial Error Patterns — Q1 2025\n\n```{r spatial_errors_q1}\nstation_errors_q1 <- test_q1 %>%\n  group_by(start_station, start_lat.x, start_lon.x) %>%\n  summarize(\n    MAE_q1         = mean(abs_error_q1, na.rm = TRUE),\n    avg_demand_q1  = mean(Trip_Count, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  filter(!is.na(start_lat.x), !is.na(start_lon.x))\n\np1_q1 <- ggplot() +\n  geom_sf(data = philly_census_q1, fill = \"grey95\", color = \"white\", size = 0.2) +\n  geom_point(\n    data = station_errors_q1,\n    aes(x = start_lon.x, y = start_lat.x, color = MAE_q1),\n    size = 3.5,\n    alpha = 0.7\n  ) +\n  scale_color_viridis(\n    option = \"plasma\",\n    name = \"MAE (trips)\",\n    direction = -1\n  ) +\n  labs(title = \"Prediction Errors — Q1 2025\") +\n  mapTheme +\n  theme(legend.position = \"bottom\")\n\np2_q1 <- ggplot() +\n  geom_sf(data = philly_census_q1, fill = \"grey95\", color = \"white\", size = 0.2) +\n  geom_point(\n    data = station_errors_q1,\n    aes(x = start_lon.x, y = start_lat.x, color = avg_demand_q1),\n    size = 3.5,\n    alpha = 0.7\n  ) +\n  scale_color_viridis(\n    option = \"viridis\",\n    name = \"Avg Demand (trips/hr)\",\n    direction = -1\n  ) +\n  labs(title = \"Average Demand — Q1 2025\") +\n  mapTheme +\n  theme(legend.position = \"bottom\")\n\ngrid.arrange(p1_q1, p2_q1, ncol = 2)\n```\n\n## Temporal Error Patterns — Q1 2025\n\n```{r temporal_errors_q1}\ntemporal_errors_q1 <- test_q1 %>%\n  group_by(time_of_day_q1, weekend) %>%\n  summarize(\n    MAE_q1 = mean(abs_error_q1, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  mutate(day_type_q1 = ifelse(weekend == 1, \"Weekend\", \"Weekday\"))\n\nggplot(temporal_errors_q1, aes(x = time_of_day_q1, y = MAE_q1, fill = day_type_q1)) +\n  geom_col(position = \"dodge\") +\n  scale_fill_manual(values = c(\"Weekday\" = \"#08519c\", \"Weekend\" = \"#6baed6\")) +\n  labs(\n    title = \"Prediction Errors by Time of Day — Q1 2025\",\n    x = \"Time of Day\",\n    y = \"Mean Absolute Error (trips)\"\n  ) +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n## Errors vs. Demographics — Q1 2025\n\n```{r errors_demographics_q1}\nstation_errors_demo_q1 <- station_errors_q1 %>%\n  left_join(\n    station_attributes_q1 %>%\n      select(start_station, Med_Inc, Percent_Taking_Transit, Percent_White),\n    by = \"start_station\"\n  ) %>%\n  filter(!is.na(Med_Inc))\n\np1_q1 <- ggplot(station_errors_demo_q1, aes(x = Med_Inc, y = MAE_q1)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  scale_x_continuous(labels = scales::dollar) +\n  labs(x = \"Median Income\", y = \"MAE\") +\n  plotTheme\n\np2_q1 <- ggplot(station_errors_demo_q1, aes(x = Percent_Taking_Transit, y = MAE_q1)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(x = \"% Taking Transit\", y = \"MAE\") +\n  plotTheme\n\np3_q1 <- ggplot(station_errors_demo_q1, aes(x = Percent_White, y = MAE_q1)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(x = \"% White\", y = \"MAE\") +\n  plotTheme\n\ngrid.arrange(p1_q1, p2_q1, p3_q1, ncol = 2)\n```\n\n# INDEGO TRIP DATA Q2 2024\n\n## Load Indego Trip Data (Q2 2024)\n\n```{r}\n#| echo: false\n#| message: false \n#| output: false\n# Read Q1 2025 data\nindego <- read_csv(here(\"C:/Users/chloe.robinson/Desktop/PENN/FALL 2025/Public Policy Analytics/Week 1/portfolio-setup-chloelr/Labs/Lab 5/Data/indego-trips-2024-q2.csv\"))\n\n# Quick look at the data\nglimpse(indego)\n```\n\n```{r}\n#| echo: false\n#| results: hide\n#| message: false\n#| warning: false\n# How many trips?\ncat(\"Total trips in Q2 2024:\", nrow(indego), \"\\n\")\n\n# Date range\ncat(\"Date range:\", \n    min(mdy_hm(indego$start_time)), \"to\", \n    max(mdy_hm(indego$start_time)), \"\\n\")\n\n# How many unique stations?\ncat(\"Unique start stations:\", length(unique(indego$start_station)), \"\\n\")\n\n# Trip types\ntable(indego$trip_route_category)\n\n# Passholder types\ntable(indego$passholder_type)\n\n# Bike types\ntable(indego$bike_type)\n```\n\n```{r summary_table}\n#| echo: false\n#| message: false\n#| warning: false\n\nsummary_table <- tibble(\n  `Total Trips`           = nrow(indego),\n  `Date Range Start`      = min(mdy_hm(indego$start_time)),\n  `Date Range End`        = max(mdy_hm(indego$start_time)),\n  `Unique Start Stations` = length(unique(indego$start_station))\n)\n\nkable(summary_table, caption = \"Summary of Indego Trip Data\") |>\n  kable_styling(latex_options = \"hold_position\")\n```\n\n## Create Time Bins\n\nWe need to aggregate trips into hourly intervals for our panel data structure.\n\n```{r}\nindego <- indego %>%\n  mutate(\n    # Parse datetime\n    start_datetime = mdy_hm(start_time),\n    end_datetime = mdy_hm(end_time),\n    \n    # Create hourly bins\n    interval60 = floor_date(start_datetime, unit = \"hour\"),\n    \n    # Extract time features\n    week = week(interval60),\n    month = month(interval60, label = TRUE),\n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    date = as.Date(interval60),\n    \n    # Create useful indicators\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n```\n\n```{r}\n#| echo: false\nindego %>%\n  select(start_datetime, interval60, week, dotw, hour, weekend) %>%\n  head(10) %>%\n  kable(caption = \"Preview of temporal features\") %>%\n  kable_styling(latex_options = c(\"striped\", \"hold_position\"))\n```\n\n------------------------------------------------------------------------\n\n# Exploratory Analysis\n\n## Trips Over Time\n\n```{r}\n# Daily trip counts\ndaily_trips <- indego %>%\n  group_by(date) %>%\n  summarize(trips = n())\n\nggplot(daily_trips, aes(x = date, y = trips)) +\n  geom_line(color = \"#3182bd\", linewidth = 1) +\n  geom_smooth(se = FALSE, color = \"red\", linetype = \"dashed\") +\n  labs(\n    title = \"Indego Daily Ridership - Q2 2024\",\n    subtitle = \"Spring Demand Paters in Philadelphia\",\n    x = \"Date\",\n    y = \"Daily Trips\",\n    caption = \"Source: Indego bike share\"\n  ) +\n  plotTheme\n```\n\nIndego ridership increases at a steady pace from April through June, showing a clear upward seasonal trend as the weather improves. Although overall ridership rises over time, there are occasional dips and highs that likely reflect bad weather or special events in Philadelphia.\n\n## Hourly Patterns\n\n```{r hourly_patterns}\n# Average trips by hour and day type\nhourly_patterns <- indego %>%\n  group_by(hour, weekend) %>%\n  summarize(avg_trips = n() / n_distinct(date)) %>%\n  mutate(day_type = ifelse(weekend == 1, \"Weekend\", \"Weekday\"))\n\nggplot(hourly_patterns, aes(x = hour, y = avg_trips, color = day_type)) +\n  geom_line(linewidth = 1.2) +\n  scale_color_manual(values = c(\"Weekday\" = \"#08519c\", \"Weekend\" = \"#6baed6\")) +\n  labs(\n    title = \"Average Hourly Ridership Patterns\",\n    subtitle = \"Clear commute patterns on weekdays\",\n    x = \"Hour of Day\",\n    y = \"Average Trips per Hour\",\n    color = \"Day Type\"\n  ) +\n  plotTheme\n```\n\nThe chart shows a strong correlation between commuting times and ridership during the weekday. There is a clear spike during the morning commute time during the week at 9am, and an even higher spike in ridership during the evening peak commute time, around 5-6pm. In contrast, the weekend pattern does not show sharp ridership peaks, instead has a steady ridership rises later in the morning, stays spread out across the afternoon, and begins to decline at 3pm.\n\n## Top Stations\n\n```{r top_stations}\n# Most popular origin stations\ntop_stations <- indego %>%\n  count(start_station, start_lat, start_lon, name = \"trips\") %>%\n  arrange(desc(trips)) %>%\n  head(10)\n```\n\n```{r top_stations_table}\n#| echo: false\nkable(top_stations, \n      caption = \"Top 10 Indego Stations by Trip Origins\",\n      format.args = list(big.mark = \",\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n------------------------------------------------------------------------\n\n# Get Philadelphia Spatial Context\n\n## Load Philadelphia Census Data + Map Context\n\n```{r load_census}\n#| echo: false\n#| results: hide\n#| message: false\n#| warning: false\n\n# Get Philadelphia census tracts\nphilly_census <- get_acs(\n  geography = \"tract\",\n  variables = c(\n    \"B01003_001\",  # Total population\n    \"B19013_001\",  # Median household income\n    \"B08301_001\",  # Total commuters\n    \"B08301_010\",  # Commute by transit\n    \"B02001_002\",  # White alone\n    \"B25077_001\"   # Median home value\n  ),\n  state = \"PA\",\n  county = \"Philadelphia\",\n  year = 2022,\n  geometry = TRUE,\n  output = \"wide\"\n) %>%\n  rename(\n    Total_Pop = B01003_001E,\n    Med_Inc = B19013_001E,\n    Total_Commuters = B08301_001E,\n    Transit_Commuters = B08301_010E,\n    White_Pop = B02001_002E,\n    Med_Home_Value = B25077_001E\n  ) %>%\n  mutate(\n    Percent_Taking_Transit = (Transit_Commuters / Total_Commuters) * 100,\n    Percent_White = (White_Pop / Total_Pop) * 100\n  ) %>%\n  st_transform(crs = 4326)  # WGS84 for lat/lon matching\n\n# Check the data\nglimpse(philly_census)\n```\n\n## Map Philadelphia Context\n\n```{r map_philly}\n# Map median income\nggplot() +\n  geom_sf(data = philly_census, aes(fill = Med_Inc), color = NA) +\n  scale_fill_viridis(\n    option = \"viridis\",\n    name = \"Median\\nIncome\",\n    labels = scales::dollar\n  ) +\n  labs(\n    title = \"Philadelphia Median Household Income by Census Tract\",\n    subtitle = \"Context for understanding bike share demand patterns\"\n  ) +\n  # Stations \n  geom_point(\n    data = indego,\n    aes(x = start_lon, y = start_lat),\n    color = \"red\", size = 0.25, alpha = 0.6\n  ) +\n  mapTheme\n```\n\n## Join Census Data to Stations\n\nWe'll spatially join census characteristics to each bike station.\n\n```{r join_census_to_stations}\n# Create sf object for stations\nstations_sf <- indego %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  st_as_sf(coords = c(\"start_lon\", \"start_lat\"), crs = 4326)\n\n# Spatial join to get census tract for each station\nstations_census <- st_join(stations_sf, philly_census, left = TRUE) %>%\n  st_drop_geometry()\n\n# Look at the result - investigate whether all of the stations joined to census data\n\nstations_for_map <- indego %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  left_join(\n    stations_census %>% select(start_station, Med_Inc),\n    by = \"start_station\"\n  ) %>%\n  mutate(has_census = !is.na(Med_Inc))\n\n# Add back to trip data\nindego_census <- indego %>%\n  left_join(\n    stations_census %>% \n      select(start_station, Med_Inc, Percent_Taking_Transit, \n             Percent_White, Total_Pop),\n    by = \"start_station\"\n  )\n```\n\n```{r join_census_to_stations2}\n#| echo: false\n# Prepare data for visualization\nstations_for_map <- indego %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  left_join(\n    stations_census %>% select(start_station, Med_Inc),\n    by = \"start_station\"\n  ) %>%\n  mutate(has_census = !is.na(Med_Inc))\n\n# Create the map showing problem stations\nggplot() +\n  geom_sf(data = philly_census, aes(fill = Med_Inc), color = \"white\", size = 0.1) +\n  scale_fill_viridis(\n    option = \"viridis\",\n    name = \"Median\\nIncome\",\n    labels = scales::dollar,\n    na.value = \"grey90\"\n  ) +\n  # Stations with census data (small grey dots)\n  geom_point(\n    data = stations_for_map %>% filter(has_census),\n    aes(x = start_lon, y = start_lat),\n    color = \"grey30\", size = 1, alpha = 0.6\n  ) +\n  # Stations WITHOUT census data (red X marks the spot)\n  geom_point(\n    data = stations_for_map %>% filter(!has_census),\n    aes(x = start_lon, y = start_lat),\n    color = \"red\", size = 1, shape = 4, stroke = 1.5\n  ) +\n  labs(\n    title = \"Philadelphia Median Household Income by Census Tract\",\n    subtitle = \"Indego stations shown (RED = no census data match)\",\n    caption = \"Red X marks indicate stations that didn't join to census tracts\"\n  ) +\n  mapTheme\n```\n\n# Dealing with missing data\n\nWe need to decide what to do with the non-residential bike share stations. For this example, we are going to remove them -- this is not necessarily the right way to do things always, but for the sake of simplicity, we are narrowing our scope to only stations in residential neighborhoods. We might opt to create a separate model for non-residential stations..\n\n```{r}\n# Identify which stations to keep\nvalid_stations <- stations_census %>%\n  filter(!is.na(Med_Inc)) %>%\n  pull(start_station)\n\n# Filter trip data to valid stations only\nindego_census <- indego %>%\n  filter(start_station %in% valid_stations) %>%\n  left_join(\n    stations_census %>% \n      select(start_station, Med_Inc, Percent_Taking_Transit, \n             Percent_White, Total_Pop),\n    by = \"start_station\"\n  )\n\n```\n\n# Get Weather Data\n\nWeather significantly affects bike share demand! Let's get hourly weather for Philadelphia.\n\n```{r get_weather}\n# Get weather from Philadelphia International Airport (KPHL)\n# This covers Q2 2024: April 1 - June 30\nweather_data <- riem_measures(\n  station = \"PHL\",  # Philadelphia International Airport\n  date_start = \"2024-04-01\",\n  date_end = \"2024-06-30\"\n)\n\n# Process weather data\nweather_processed <- weather_data %>%\n  mutate(\n    interval60 = floor_date(valid, unit = \"hour\"),\n    Temperature = tmpf,  # Temperature in Fahrenheit\n    Precipitation = ifelse(is.na(p01i), 0, p01i),  # Hourly precip in inches\n    Wind_Speed = sknt  # Wind speed in knots\n  ) %>%\n  select(interval60, Temperature, Precipitation, Wind_Speed) %>%\n  distinct()\n\n# Check for missing hours and interpolate if needed\nweather_complete <- weather_processed %>%\n  complete(interval60 = seq(min(interval60), max(interval60), by = \"hour\")) %>%\n  fill(Temperature, Precipitation, Wind_Speed, .direction = \"down\")\n```\n\n## Visualize Weather Patterns\n\n```{r visualize_weather}\n#| echo: false\nggplot(weather_complete, aes(x = interval60, y = Temperature)) +\n  geom_line(color = \"#3182bd\", alpha = 0.7) +\n  geom_smooth(se = FALSE, color = \"red\") +\n  labs(\n    title = \"Philadelphia Temperature - Q2 2024\",\n    subtitle = \"Winter to early spring transition\",\n    x = \"Date\",\n    y = \"Temperature (°F)\"\n  ) +\n  plotTheme\n```\n\n------------------------------------------------------------------------\n\n# Create Space-Time Panel\n\n## Aggregate Trips to Station-Hour Level\n\n```{r aggregate_trips_1}\n# Count trips by station-hour\ntrips_panel <- indego_census %>%\n  group_by(interval60, start_station, start_lat, start_lon,\n           Med_Inc, Percent_Taking_Transit, Percent_White, Total_Pop) %>%\n  summarize(Trip_Count = n()) %>%\n  ungroup()\n```\n\n```{r aggregate_trips}\n#| echo: false\nsummary_counts <- tibble(\n  Metric = c(\n    \"Total Station-Hour Observations\",\n    \"Unique Stations\",\n    \"Unique Hours\"\n  ),\n  Value = c(\n    nrow(trips_panel),\n    length(unique(trips_panel$start_station)),\n    length(unique(trips_panel$interval60))\n  )\n)\n\nsummary_counts %>%\n  kable(\n    caption = \"Summary of Panel Structure\",\n    col.names = c(\"Metric\", \"Value\"),\n    format.args = list(big.mark = \",\")\n  ) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n## Create Complete Panel Structure\n\nNot every station has trips every hour. We need a **complete panel** where every station-hour combination exists (even if Trip_Count = 0).\n\n```{r complete_panel}\n# Calculate expected panel size\nn_stations <- length(unique(trips_panel$start_station))\nn_hours <- length(unique(trips_panel$interval60))\nexpected_rows <- n_stations * n_hours\n```\n\n```{r complete_panel_summary}\n#| echo: false\n# Create summary table\npanel_summary <- tibble(\n  Metric = c(\"Expected panel rows\",\n             \"Current rows\",\n             \"Missing rows\"),\n  Value = c(expected_rows,\n            nrow(trips_panel),\n            expected_rows - nrow(trips_panel))\n)\n\n# Format numbers with commas\npanel_summary$Value <- format(panel_summary$Value, big.mark = \",\")\n\n# Display clean table\nkable(panel_summary,\n      caption = \"Completeness of Panel Structure\") |>\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n```{r complete_panel_summary_2}\n# Create complete panel\nstudy_panel <- expand.grid(\n  interval60 = unique(trips_panel$interval60),\n  start_station = unique(trips_panel$start_station)\n) %>%\n  # Join trip counts\n  left_join(trips_panel, by = c(\"interval60\", \"start_station\")) %>%\n  # Replace NA trip counts with 0\n  mutate(Trip_Count = replace_na(Trip_Count, 0))\n\n# Fill in station attributes (they're the same for all hours)\nstation_attributes <- trips_panel %>%\n  group_by(start_station) %>%\n  summarize(\n    start_lat = first(start_lat),\n    start_lon = first(start_lon),\n    Med_Inc = first(Med_Inc),\n    Percent_Taking_Transit = first(Percent_Taking_Transit),\n    Percent_White = first(Percent_White),\n    Total_Pop = first(Total_Pop)\n  )\n\nstudy_panel <- study_panel %>%\n  left_join(station_attributes, by = \"start_station\")\n```\n\n```{r complete_panel_summary_3}\n#| echo: false\ncomplete_panel_summary <- tibble(\nMetric = \"Complete panel rows\",\nValue = format(nrow(study_panel), big.mark = \",\")\n)\n\nkable(complete_panel_summary,\ncaption = \"Final Panel Size After Completion\") |>\nkable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n## Add Time Features\n\n```{r add_time_features}\nstudy_panel <- study_panel %>%\n  mutate(\n    week = week(interval60),\n    month = month(interval60, label = TRUE),\n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    date = as.Date(interval60),\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n```\n\n## Join Weather Data\n\n```{r join_weather}\nstudy_panel <- study_panel %>%\n  left_join(weather_complete, by = \"interval60\")\n```\n\n------------------------------------------------------------------------\n\n# Create Temporal Lag Variables\n\nThe key innovation for space-time prediction: **past demand predicts future demand**.\n\n## Why Lags?\n\nIf there were 15 bike trips from Station A at 8:00 AM, there will probably be \\~15 trips at 9:00 AM. We can use this temporal persistence to improve predictions.\n\n```{r create_lags}\n# Sort by station and time\nstudy_panel <- study_panel %>%\n  arrange(start_station, interval60)\n\n# Create lag variables WITHIN each station\nstudy_panel <- study_panel %>%\n  group_by(start_station) %>%\n  mutate(\n    lag1Hour = lag(Trip_Count, 1),\n    lag2Hours = lag(Trip_Count, 2),\n    lag3Hours = lag(Trip_Count, 3),\n    lag12Hours = lag(Trip_Count, 12),\n    lag1day = lag(Trip_Count, 24)\n  ) %>%\n  ungroup()\n\n# Remove rows with NA lags (first 24 hours for each station)\nstudy_panel_complete <- study_panel %>%\n  filter(!is.na(lag1day))\n\nstudy_panel_complete <- study_panel_complete %>%\n  mutate(\n    month = factor(month, levels = c(\"Apr\", \"May\", \"Jun\")),\n    dotw  = factor(dotw,  levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"))\n  )\n```\n\n## Visualize Lag Correlations\n\n```{r lag_correlations}\n# Sample one station to visualize\nexample_station <- study_panel_complete %>%\n  filter(start_station == first(start_station)) %>%\n  head(168)  # One week\n\n# Plot actual vs lagged demand\nggplot(example_station, aes(x = interval60)) +\n  geom_line(aes(y = Trip_Count, color = \"Current\"), linewidth = 1) +\n  geom_line(aes(y = lag1Hour, color = \"1 Hour Ago\"), linewidth = 1, alpha = 0.7) +\n  geom_line(aes(y = lag1day, color = \"24 Hours Ago\"), linewidth = 1, alpha = 0.7) +\n  scale_color_manual(values = c(\n    \"Current\" = \"#08519c\",\n    \"1 Hour Ago\" = \"#3182bd\",\n    \"24 Hours Ago\" = \"#6baed6\"\n  )) +\n  labs(\n    title = \"Temporal Lag Patterns at One Station\",\n    subtitle = \"Past demand predicts future demand\",\n    x = \"Date-Time\",\n    y = \"Trip Count\",\n    color = \"Time Period\"\n  ) +\n  plotTheme\n```\n\n------------------------------------------------------------------------\n\n# Temporal Train/Test Split\n\n**CRITICAL:** We must train on PAST data and test on FUTURE data!\n\n## Why Temporal Validation Matters\n\nIn real operations, at 6:00 AM on March 15, we need to predict demand for March 15-31. We have data from Jan 1 - March 14, but NOT from March 15-31 (it hasn't happened yet!).\n\n**Wrong approach:** Train on weeks 10-13, test on weeks 1-9 (predicting past from future!)\n\n**Correct approach:** Train on weeks 1-9, test on weeks 10-13 (predicting future from past)\n\n```{r temporal_split}\n# Split by week for Q2 2024\n# Q2 has weeks 14–26 (April–June)\n# Train on weeks 14–21 (April–late May)\n# Test on weeks 22–26 (mostly June)\n\ntrain_weeks <- 14:21\ntest_weeks  <- 22:26\n\n# Stations active in BOTH early (train) and late (test) periods\nearly_stations <- study_panel_complete %>%\n  filter(week %in% train_weeks, Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\nlate_stations <- study_panel_complete %>%\n  filter(week %in% test_weeks, Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\ncommon_stations <- intersect(early_stations, late_stations)\n\n# Keep only common stations\nstudy_panel_q2 <- study_panel_complete %>%\n  filter(start_station %in% common_stations)\n\n# Now create train/test split\ntrain <- study_panel_q2 %>%\n  filter(week %in% train_weeks)\n\ntest <- study_panel_q2 %>%\n  filter(week %in% test_weeks)\n```\n\n```{r summary 2}\n#| echo: false\nsummary_table <- tibble(\n  Set = c(\"Training\", \"Testing\"),\n  Observations = c(nrow(train), nrow(test)),\n  Date_Range = c(\n    paste(min(train$date), \"to\", max(train$date)),\n    paste(min(test$date), \"to\", max(test$date))\n  )\n)\n\nkable(summary_table, format = \"latex\", booktabs = TRUE, caption = \"Train/Test Summary\") %>%\n  kable_styling(latex_options = c(\"striped\", \"hold_position\"))\n```\n\n------------------------------------------------------------------------\n\n# Build Predictive Models\n\nWe'll build 5 models with increasing complexity to see what improves predictions.\n\n## Model 1: Baseline (Time + Weather)\n\n```{r model1}\n\n# Create day of week factor with treatment (dummy) coding\ntrain <- train %>%\n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\n# Set contrasts to treatment coding (dummy variables)\ncontrasts(train$dotw_simple) <- contr.treatment(7)\n\n# Now run the model\nmodel1 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation,\n  data = train\n)\n\n```\n\nThe model uses Monday as the baseline. Each coefficient represents the difference in expected trips per station-hour compared to Monday - dow_simple2 = Tuesday..\n\n**Weekday Pattern (Tue-Fri):**\n\n-   Weekday effects range from –0.063 to +0.016.\n-   No weekday has a positive, strong increase, unlike your example.\n-   Thursday is the only weekday above baseline.\n-   Tuesday, Wednesday, and Friday are all slightly below Monday.\n\n**Weekend Pattern (Sat-Sun):**\n\n-   Both weekend days show substantial drops relative to Monday.\n-   Sunday has the largest negative effect (–0.112).\n-   This indicates significantly lower station-hour activity on weekends.\n\n**Hourly Interpretation**\n\nAcross the 24-hour day, activity is lowest between hours 1–4, where trips fall slightly below the midnight baseline (with coefficients between -0.078 and -0.096). Activity begins to rise at hour 5 (+0.033) and increases sharply through the morning commute, with strong positive effects at hours 6–9, including a substantial morning peak at hour 8 (+0.851) and sustained high demand at hour 9 (+0.637). Midday hours (10–14) maintain moderately elevated trip counts, ranging from +0.535 to +0.643. In the afternoon, demand climbs again, rising through hours 15–16 and reaching the highest level of the entire day at hour 17 (+1.161), indicating a very strong evening peak. Activity remains high at hour 18 (+0.917) before gradually declining across the evening hours 19–22 (from +0.672 down to +0.186). By hour 23, demand tapers to a modest +0.065—still slightly above the midnight baseline but representing the transition into late-night low activity.\n\nIsn't this fun!\n\n## Model 2: Add Temporal Lags\n\n```{r model2}\nmodel2 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day,\n  data = train\n)\n```\n\nThe inclusion of temporal lags substantially improved the model’s explanatory power, raising the adjusted R² from approximately 0.116 to 0.348, which reflects a nearly threefold increase in explained variation. This improvement occurs because bike-share demand is highly autocorrelated: stations that experience high or low usage in one hour tend to show similar patterns in the following hours, and usage at the same hour on the previous day is also strongly predictive. The lagged variables, particularly the one-hour lag and the three-hour and one-day lags, capture these short-term and daily cyclical patterns that the hour-of-day and day-of-week predictors alone can't do. As a result, the model better reflects the underlying temporal structure of bike demand, leading to smaller residuals and a much stronger overall fit.\n\n## Model 3: Add Demographics\n\n```{r model3}\n#| results: hide\n#| message: false\n#| warning: false\n\nmodel3 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day +\n    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y,\n  data = train\n)\n\nsummary(model3)\n```\n\nThe addition of demographic variables did not improve model fit; in fact, the adjusted R² declined from about 0.348 in the temporal-lag model to roughly 0.237 after including median income, transit use, and racial composition. This reduction occurs primarily because adding demographics caused the loss of over 270,000 observations due to missing data, leaving the model trained on less than one-third of the original sample. With far fewer observations, the hour-to-hour temporal structure that drives trip volume becomes harder to estimate precisely, and the remaining sample may not fully represent the full behavioral patterns across the system. Although two demographic predictors, percent taking transit and percent white are statistically significant, their effect sizes are small relative to the strong temporal autocorrelation captured by the lagged variables. As a result, the demographic-augmented model explains less variance overall, not because demographics are irrelevant, but because the loss of data outweighs any modest predictive gains they could have contributed.\n\n## Model 4: Add Station Fixed Effects\n\n```{r model4}\nmodel4 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day +\n    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y +\n    as.factor(start_station),\n  data = train\n)\n\n# Summary too long with all station dummies, just show key metrics\ncat(\"Model 4 R-squared:\", summary(model4)$r.squared, \"\\n\")\ncat(\"Model 4 Adj R-squared:\", summary(model4)$adj.r.squared, \"\\n\")\n```\n\nAdding station fixed effects allows the model to account for persistent, station-specific differences in baseline trip demand that are not explained by hourly patterns, day-of-week effects, weather, lags, or demographics. Some stations are inherently busier because they are located in dense commercial districts, near major transit hubs, or along popular commuting corridors, while others serve quieter residential or peripheral areas with consistently lower usage. By including a dummy variable for each station, the model absorbs these stable location-level characteristics, effectively letting every station have its own intercept and preventing unobserved spatial differences from biasing the other coefficients. Although this raises the R-squared relative to the demographics-only model, the improvement is moderate because fixed effects mainly redistribute variance across stations rather than improving the model’s ability to explain within station temporal fluctuations, which are still driven primarily by the lag terms and hourly patterns.\n\n## Model 5: Add Rush Hour Interaction\n\n```{r model5}\ntrain$month <- factor(train$month, levels = c(\"Apr\", \"May\", \"Jun\"))\ntest$month <- factor(test$month, levels = levels(train$month))\n\nmodel5 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day + rush_hour + month +\n    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y +\n    as.factor(start_station) +\n    rush_hour * weekend,  # Rush hour effects different on weekends\n  data = train\n)\n```\n\nModel 5 adds a rush_hour × weekend interaction to allow peak-period effects to differ between weekdays and weekends. This recognizes that weekday rush hours reflect strong commuting patterns, while weekend usage is more diffuse and less time-sensitive. By including this interaction, along with month fixed effects, the model captures important behavioral differences in how riders use the system across days and times, refining the temporal structure established in earlier models.\n\n------------------------------------------------------------------------\n\n# Model Evaluation\n\n## Calculate Predictions and MAE\n\n```{r calculate_mae}\n# Get predictions on test set\n\n# Make sure month in TEST has the same levels as train\ntest$month <- factor(test$month, levels = model5$xlevels$month)\n\n# Create day of week factor with treatment (dummy) coding\ntest <- test %>%\n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\n# Set contrasts to treatment coding (dummy variables)\ncontrasts(test$dotw_simple) <- contr.treatment(7)\n\ntest <- test %>%\n  mutate(\n    pred1 = predict(model1, newdata = test),\n    pred2 = predict(model2, newdata = test),\n    pred3 = predict(model3, newdata = test),\n    pred4 = predict(model4, newdata = test),\n    pred5 = predict(model5, newdata = test)\n  )\n\n# Calculate MAE for each model\nmae_results <- data.frame(\n  Model = c(\n    \"1. Time + Weather\",\n    \"2. + Temporal Lags\",\n    \"3. + Demographics\",\n    \"4. + Station FE\",\n    \"5. + Rush Hour Interaction\"\n  ),\n  MAE = c(\n    mean(abs(test$Trip_Count - test$pred1), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred2), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred3), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred4), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred5), na.rm = TRUE)\n  )\n)\n\nkable(mae_results, \n      digits = 2,\n      caption = \"Mean Absolute Error by Model (Test Set)\",\n      col.names = c(\"Model\", \"MAE (trips)\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n## Visualize Model Comparison\n\n```{r compare_models}\nggplot(mae_results, aes(x = reorder(Model, -MAE), y = MAE)) +\n  geom_col(fill = \"#3182bd\", alpha = 0.8) +\n  geom_text(aes(label = round(MAE, 2)), vjust = -0.5) +\n  labs(\n    title = \"Model Performance Comparison\",\n    subtitle = \"Lower MAE = Better Predictions\",\n    x = \"Model\",\n    y = \"Mean Absolute Error (trips)\"\n  ) +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n**Question:** Which features gave us the biggest improvement?\n\nFor Q2 2024, the features that helped the most were the temporal lags (Model 2). When we added the 1-hour, 3-hour, and 24-hour lag variables, the MAE dropped the most, from 0.86 down to 0.71. This makes sense because bike demand tends to repeat patterns from the previous hour or the same hour yesterday.\n\n------------------------------------------------------------------------\n\n# Space-Time Error Analysis\n\n## Observed vs. Predicted\n\nLet's use our best model (Model 2) for error analysis.\n\n```{r obs_vs_pred}\ntest <- test %>%\n  mutate(\n    error = Trip_Count - pred2,\n    abs_error = abs(error),\n    time_of_day = case_when(\n      hour < 7 ~ \"Overnight\",\n      hour >= 7 & hour < 10 ~ \"AM Rush\",\n      hour >= 10 & hour < 15 ~ \"Mid-Day\",\n      hour >= 15 & hour <= 18 ~ \"PM Rush\",\n      hour > 18 ~ \"Evening\"\n    )\n  )\n\n# Scatter plot by time and day type\nggplot(test, aes(x = Trip_Count, y = pred2)) +\n  geom_point(alpha = 0.2, color = \"#3182bd\") +\n  geom_abline(slope = 1, intercept = 0, color = \"red\", linewidth = 1) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"darkgreen\") +\n  facet_grid(weekend ~ time_of_day) +\n  labs(\n    title = \"Observed vs. Predicted Bike Trips\",\n    subtitle = \"Model 2 performance by time period\",\n    x = \"Observed Trips\",\n    y = \"Predicted Trips\",\n    caption = \"Red line = perfect predictions; Green line = actual model fit\"\n  ) +\n  plotTheme\n```\n\n**Question:** Where is the model performing well? Where is it struggling?\n\nThe model performs best during Mid-Day and Overnight hours, where points fall close to the 45° line and the green fitted line tracks the red perfect-prediction line more closely. It performs worst during AM Rush and PM Rush, especially on weekdays, where the model systematically under-predicts higher ridership and shows much wider scatter. Evening periods also show moderate under-prediction but less extreme than the rush hours.\n\n## Spatial Error Patterns\n\nAre prediction errors clustered in certain parts of Philadelphia?\n\n```{r spatial_errors}\n# Calculate MAE by station\nstation_errors <- test %>%\n  group_by(start_station, start_lat.x, start_lon.y) %>%\n  summarize(\n    MAE = mean(abs_error, na.rm = TRUE),\n    avg_demand = mean(Trip_Count, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  filter(!is.na(start_lat.x), !is.na(start_lon.y))\n\n## Create Two Maps Side-by-Side with Proper Legends (sorry these maps are ugly)\n\n# Calculate station errors\nstation_errors <- test %>%\n  filter(!is.na(pred2)) %>%\n  group_by(start_station, start_lat.x, start_lon.y) %>%\n  summarize(\n    MAE = mean(abs(Trip_Count - pred2), na.rm = TRUE),\n    avg_demand = mean(Trip_Count, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  filter(!is.na(start_lat.x), !is.na(start_lon.y))\n\n# Map 1: Prediction Errors\np1 <- ggplot() +\n  geom_sf(data = philly_census, fill = \"grey95\", color = \"white\", size = 0.2) +\n  geom_point(\n    data = station_errors,\n    aes(x = start_lon, y = start_lat, color = MAE),\n    size = 3.5,\n    alpha = 0.7\n  ) +\n  scale_color_viridis(\n    option = \"plasma\",\n    name = \"MAE\\n(trips)\",\n    direction = -1,\n    breaks = c(0.5, 1.0, 1.5),  # Fewer, cleaner breaks\n    labels = c(\"0.5\", \"1.0\", \"1.5\")\n  ) +\n  labs(title = \"Prediction Errors\",\n       subtitle = \"Higher in Center City\") +\n  mapTheme +\n  theme(\n    legend.position = \"right\",\n    legend.title = element_text(size = 10, face = \"bold\"),\n    legend.text = element_text(size = 9),\n    plot.title = element_text(size = 14, face = \"bold\"),\n    plot.subtitle = element_text(size = 10)\n  ) +\n  guides(color = guide_colorbar(\n    barwidth = 1.5,\n    barheight = 12,\n    title.position = \"top\",\n    title.hjust = 0.5\n  ))\n\n# Map 2: Average Demand\np2 <- ggplot() +\n  geom_sf(data = philly_census, fill = \"grey95\", color = \"white\", size = 0.2) +\n  geom_point(\n    data = station_errors,\n    aes(x = start_lon.y, y = start_lat.x, color = avg_demand),\n    size = 3.5,\n    alpha = 0.7\n  ) +\n  scale_color_viridis(\n    option = \"viridis\",\n    name = \"Avg\\nDemand\",\n    direction = -1,\n    breaks = c(0.5, 1.0, 1.5, 2.0, 2.5),  # Clear breaks\n    labels = c(\"0.5\", \"1.0\", \"1.5\", \"2.0\", \"2.5\")\n  ) +\n  labs(title = \"Average Demand\",\n       subtitle = \"Trips per station-hour\") +\n  mapTheme +\n  theme(\n    legend.position = \"right\",\n    legend.title = element_text(size = 10, face = \"bold\"),\n    legend.text = element_text(size = 9),\n    plot.title = element_text(size = 14, face = \"bold\"),\n    plot.subtitle = element_text(size = 10)\n  ) +\n  guides(color = guide_colorbar(\n    barwidth = 1.5,\n    barheight = 12,\n    title.position = \"top\",\n    title.hjust = 0.5\n  ))\n\n# Map 1: Prediction Errors\np1 <- ggplot() +\n  geom_sf(data = philly_census, fill = \"grey95\", color = \"white\", size = 0.1) +\n  geom_point(\n    data = station_errors,\n    aes(x = start_lon.y, y = start_lat.x, color = MAE),\n    size = 3.5,\n    alpha = 0.7\n  ) +\n  scale_color_viridis(\n    option = \"plasma\",\n    name = \"MAE (trips)\",\n    direction = -1,\n    breaks = c(0.5, 1.0, 1.5),\n    labels = c(\"0.5\", \"1.0\", \"1.5\")\n  ) +\n  labs(title = \"Prediction Errors\") +\n  mapTheme +\n  theme(\n    legend.position = \"bottom\",\n    legend.title = element_text(size = 10, face = \"bold\"),\n    legend.text = element_text(size = 9),\n    plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5)\n  ) +\n  guides(color = guide_colorbar(\n    barwidth = 12,\n    barheight = 1,\n    title.position = \"top\",\n    title.hjust = 0.5\n  ))\n\n# Map 2: Average Demand  \np2 <- ggplot() +\n  geom_sf(data = philly_census, fill = \"grey95\", color = \"white\", size = 0.1) +\n  geom_point(\n    data = station_errors,\n    aes(x = start_lon.y, y = start_lat.x, color = avg_demand),\n    size = 3.5,\n    alpha = 0.7\n  ) +\n  scale_color_viridis(\n    option = \"viridis\",\n    name = \"Avg Demand (trips/hour)\",\n    direction = -1,\n    breaks = c(0.5, 1.0, 1.5, 2.0, 2.5),\n    labels = c(\"0.5\", \"1.0\", \"1.5\", \"2.0\", \"2.5\")\n  ) +\n  labs(title = \"Average Demand\") +\n  mapTheme +\n  theme(\n    legend.position = \"bottom\",\n    legend.title = element_text(size = 10, face = \"bold\"),\n    legend.text = element_text(size = 9),\n    plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5)\n  ) +\n  guides(color = guide_colorbar(\n    barwidth = 12,\n    barheight = 1,\n    title.position = \"top\",\n    title.hjust = 0.5\n  ))\n\n# Combine\ngrid.arrange(\n  p1, p2,\n  ncol = 2\n  )\n```\n\n**Question:** Do you see spatial clustering of errors? What neighborhoods have high errors?\n\nYes, there is a clear spatial clustering of errors. The highest prediction errors occur in and around Center City and University City, where demand is also highest. Outlying neighborhoods such as South Philly, West Parkside, and Northeast Philly show lower errors because demand is lower and more stable.\n\n## Temporal Error Patterns\n\nWhen are we most wrong?\n\n```{r temporal_errors}\n# MAE by time of day and day type\ntemporal_errors <- test %>%\n  group_by(time_of_day, weekend) %>%\n  summarize(\n    MAE = mean(abs_error, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  mutate(day_type = ifelse(weekend == 1, \"Weekend\", \"Weekday\"))\n\nggplot(temporal_errors, aes(x = time_of_day, y = MAE, fill = day_type)) +\n  geom_col(position = \"dodge\") +\n  scale_fill_manual(values = c(\"Weekday\" = \"#08519c\", \"Weekend\" = \"#6baed6\")) +\n  labs(\n    title = \"Prediction Errors by Time Period\",\n    subtitle = \"When is the model struggling most?\",\n    x = \"Time of Day\",\n    y = \"Mean Absolute Error (trips)\",\n    fill = \"Day Type\"\n  ) +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\nThe model performs best during the overnight and evening hours, when demand is low and stable. Errors increase during the middle of the day and are highest during the AM and PM rush periods, especially the PM commute. This makes sense because rush-hour ridership is far more volatile and sensitive to small changes in weather, work schedules, and travel patterns.\n\n## Errors and Demographics\n\nAre prediction errors related to neighborhood characteristics?\n\n```{r errors_demographics}\n# Join demographic data to station errors\nstation_errors_demo <- station_errors %>%\n  left_join(\n    station_attributes %>% select(start_station, Med_Inc, Percent_Taking_Transit, Percent_White),\n    by = \"start_station\"\n  ) %>%\n  filter(!is.na(Med_Inc))\n\n# Create plots\np1 <- ggplot(station_errors_demo, aes(x = Med_Inc, y = MAE)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  scale_x_continuous(labels = scales::dollar) +\n  labs(title = \"Errors vs. Median Income\", x = \"Median Income\", y = \"MAE\") +\n  plotTheme\n\np2 <- ggplot(station_errors_demo, aes(x = Percent_Taking_Transit, y = MAE)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(title = \"Errors vs. Transit Usage\", x = \"% Taking Transit\", y = \"MAE\") +\n  plotTheme\n\np3 <- ggplot(station_errors_demo, aes(x = Percent_White, y = MAE)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(title = \"Errors vs. Race\", x = \"% White\", y = \"MAE\") +\n  plotTheme\n\ngrid.arrange(p1, p2, p3, ncol = 2)\n```\n\n**Critical Question:** Are prediction errors systematically higher in certain demographic groups? What are the equity implications?\n\nAcross Philadelphia, prediction errors show meaningful relationships with neighborhood demographics. Errors tend to be slightly higher in stations located in higher-income or higher-percentage-White areas, suggesting the model struggles more in wealthier, less transit-dependent neighborhoods where trip patterns may be more irregular. In contrast, stations in areas with higher transit use show lower errors, likely because these neighborhoods have more stable, predictable travel demand. These patterns raise equity considerations: if models systematically underperform in certain demographic groups, operational decisions (like rebalancing) could unintentionally favor or disadvantage specific communities.\n\n------------------------------------------------------------------------\n\n# Part 2: COMPARE RESULTS BETWEEN Q1 2025 AND Q2 2024\n\n## Compare MAE Across Quarters\n\n```{r compare_mae_q1_q2}\nmae_results_q2 <- mae_results %>%\n  mutate(Quarter = \"Q2 2024\")\n\nmae_results_q1_labeled <- mae_results_q1 %>%\n  mutate(Quarter = \"Q1 2025\")\n\nmae_compare <- bind_rows(mae_results_q2, mae_results_q1_labeled)\n\nkable(mae_compare,\n      digits = 2,\n      caption = \"Model MAE Comparison: Q1 2025 vs Q2 2024\",\n      col.names = c(\"Model\", \"MAE (trips)\", \"Quarter\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\",\"hover\"))\n```\n\n## MAE Comparison Plot\n\n```{r compare_mae_plot_q1_q2}\nggplot(mae_compare,\n       aes(x = Model, y = MAE, fill = Quarter)) +\n  geom_col(position = \"dodge\") +\n  geom_text(aes(label = round(MAE, 2)),\n            position = position_dodge(width = 0.9),\n            vjust = -0.4, size = 3) +\n  labs(\n    title = \"Model Performance Across Quarters\",\n    y     = \"Mean Absolute Error (trips)\",\n    x     = \"Model\"\n  ) +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\nModels consistently perform better in Q1 2025 than in Q2 2024, with lower MAE across every specification. Winter travel is more predictable because most trips are work-related and follow a routine. In Q2 2024, ridership is higher and more random due to nicer weather, outdoor activities, and tourism, which makes predictions harder. This is why every model has lower MAE in Q1 than Q2.\n\n## Temporal Error Comparison: Q1 vs Q2\n\n```{r compare_temporal_errors_q1_q2}\n\n#Q1 2025 TEMPORAL ERRORS\ntemporal_errors_q1 <- test_q1 %>%\n  group_by(time_of_day_q1, weekend) %>%\n  summarize(\n    MAE = mean(abs_error_q1, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  mutate(\n    Day_Type = ifelse(weekend == 1, \"Weekend\", \"Weekday\"),\n    Quarter = \"Q1 2025\",\n    Time_of_Day = time_of_day_q1\n  ) %>%\n  select(Time_of_Day, MAE, Day_Type, Quarter)\n\n\n#Q2 2024 TEMPORAL ERRORS\ntemporal_errors_q2 <- test %>%        # your Q2 dataset\n  group_by(time_of_day, weekend) %>%\n  summarize(\n    MAE = mean(abs_error, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  mutate(\n    Day_Type = ifelse(weekend == 1, \"Weekend\", \"Weekday\"),\n    Quarter = \"Q2 2024\",\n    Time_of_Day = time_of_day\n  ) %>%\n  select(Time_of_Day, MAE, Day_Type, Quarter)\n\n\n#COMBINE\ntemporal_compare <- bind_rows(temporal_errors_q1, temporal_errors_q2)\n\n\n#PLOT\nggplot(temporal_compare,\n       aes(x = Time_of_Day, y = MAE, fill = Day_Type)) +\n  geom_col(position = \"dodge\") +\n  facet_wrap(~ Quarter, ncol = 2) +\n  labs(\n    title = \"Prediction Errors by Time of Day and Quarter\",\n    y = \"Mean Absolute Error (trips)\",\n    x = \"Time of Day\",\n    fill = \"Day Type\"\n  ) +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\nQ1 and Q2 have different error patterns. In Q1 2025, errors spike during morning and evening rush hours, when travel is busiest and most unpredictable. Overnight and evening hours are easiest to predict. In Q2 2024, errors are more evenly spread throughout the day because people ride more for leisure, not just commuting. Seasonal differences, like winter vs. spring, explain most of the pattern.\n\n## Feature Importance Comparison\n\n```{r compare_feature_importance_q1_q2}\nget_coef_table <- function(model, quarter_label) {\n  sm <- summary(model)$coefficients\n  tibble(\n    Variable  = rownames(sm),\n    Estimate  = sm[, 1]\n  ) %>%\n    mutate(\n      Quarter  = quarter_label,\n      Abs_Est  = abs(Estimate)\n    )\n}\n\ncoefs_q2 <- get_coef_table(model2,   \"Q2 2024\")\ncoefs_q1 <- get_coef_table(model2_q1,\"Q1 2025\")\n\nvars_focus <- c(\"Temperature\", \"Precipitation\",\n                \"lag1Hour\", \"lag3Hours\", \"lag1day\")\n\nfeature_compare <- bind_rows(coefs_q2, coefs_q1) %>%\n  filter(Variable %in% vars_focus) %>%\n  arrange(Quarter, desc(Abs_Est))\n\nkable(feature_compare,\n      digits = 3,\n      caption = \"Key Coefficient Magnitudes in Model 2 by Quarter\") %>%\n  kable_styling(bootstrap_options = c(\"striped\",\"hover\"))\n```\n\nDifferent features matter in each quarter. In Q1 2025, precipitation is the strongest predictor because winter weather sharply affects ridership. Temporal lags also matter because demand is more consistent hour to hour. In Q2 2024, lag effects are still important, but weather has a smaller impact, and trips follow more flexible patterns. Overall, winter demand depends more on weather, while spring demand depends more on regular daily patterns.\n\n------------------------------------------------------------------------\n\n# Part 3: FEATURE ENGINEERING AND MODEL IMPROVEMENT\n\n```{r feature_engineering}\nstudy_panel_complete_fe <- study_panel_complete %>%\narrange(start_station, interval60) %>%\ngroup_by(start_station) %>%\nmutate(\ncenter_city = if_else(\nstart_lon.x >= -75.18 & start_lon.x <= -75.13 &\nstart_lat.x >= 39.94 & start_lat.x <= 39.96,\n1, 0, missing = 0\n),\nrush_demand = rush_hour * Trip_Count,\nlag1week = lag(Trip_Count, 24 * 7),\nroll7day = rollmean(Trip_Count, k = 24 * 7,\nalign = \"right\", fill = NA)\n) %>%\nungroup() %>%\nmutate(\nrush_demand = replace_na(rush_demand, 0),\nlag1week = replace_na(lag1week, 0),\nroll7day = replace_na(roll7day, 0)\n)\n\n#Match train/test splits using the same rows as original objects\n\ntrain_fe <- study_panel_complete_fe %>%\nsemi_join(train %>% select(interval60, start_station),\nby = c(\"interval60\", \"start_station\"))\n\ntest_fe <- study_panel_complete_fe %>%\nsemi_join(test %>% select(interval60, start_station),\nby = c(\"interval60\", \"start_station\"))\n```\n\n# Build Improved Model (Model 2 with New Features)\n\n```{r improved_model}\nmodel2_fe <- lm(\nTrip_Count ~\nas.factor(hour) + dotw +\nTemperature + Precipitation +\nlag1Hour + lag3Hours + lag1day +\ncenter_city + rush_demand +\nlag1week + roll7day,\ndata = train_fe\n)\n```\n\n# Predict on test\n\n```{r predict_on_test}\ntest_fe <- test_fe %>%\nmutate(pred_fe = predict(model2_fe, newdata = .))\n```\n\n#MAE Comparison Old vs New model 2\n\n```{r mae_oldvsnew}\nmae_old <- mean(abs(test$Trip_Count - test$pred2), na.rm = TRUE)\nmae_new <- mean(abs(test_fe$Trip_Count - test_fe$pred_fe), na.rm = TRUE)\n\nmae_compare_fe <- tibble(\nModel = c(\"Original Model 2\", \"Improved Model 2 + New Features\"),\nMAE = c(mae_old, mae_new)\n)\n\nkable(mae_compare_fe,\ncaption = \"MAE Comparison: Original vs Improved Model\") %>%\nkable_styling(bootstrap_options = c(\"striped\",\"hover\"))\n```\n\n#Plot\n\n```{r plot_new}\nggplot(mae_compare_fe, aes(x = Model, y = MAE, fill = Model)) +\ngeom_col() +\ngeom_text(aes(label = round(MAE, 3)), vjust = -0.5) +\nlabs(\ntitle = \"Model Improvement After Feature Engineering\",\ny = \"MAE (trips)\"\n) +\nplotTheme +\ntheme(legend.position = \"none\")\n```\n\nModel 2 already included the main predictors like hour of day, day of week, weather, and a few short-term lags. But after looking at the error analysis, it was pretty clear that the model was still missing some important patterns. So I added four new features that directly targeted the biggest problems I found.\n\nThe first feature I added was a Center City indicator, because the error maps showed the model was consistently under-predicting in the downtown stations. These stations have way more activity than the rest of the city, so giving the model a simple 0/1 flag helps it separate the normal stations from the very busy ones.\n\nNext, I added rush_demand, which is rush hour × recent demand. The temporal plots showed that most of the big mistakes happened during the morning and evening commute times. This feature tells the model when a station’s demand tends to spike specifically during rush hour, which helps reduce under-prediction during those busy periods.\n\nI also added lag1week, which is the same hour from the previous week. The data showed strong weekly patterns. The original model only looked back a few hours or one day, so adding this weekly lag helps the model pick up those repeating patterns.\n\nAnd last, I added roll7day, the 7-day rolling average. Hour-to-hour demand can be really noisy, so this gives the model a smoother signal showing whether demand at a station has been trending up or down over the last week. This helps make predictions more stable instead of jumping around from one random spike.\n\nTogether, these four features directly address the main issues found in the error analysis and help the model make more consistent and accurate predictions.\n\n------------------------------------------------------------------------\n\n## Part 4: Critical Reflection\n\n1.  **Operational implications:** Even though my improved model has a fairly low MAE, it still isn’t perfect, and Indego would need to be careful about relying on it. Most of the time, an MAE under 1 trip is “good enough” to guide rebalancing decisions, but errors during rush hour or at busy downtown stations can still cause real problems. A station emptying out 2–3 bikes earlier than expected can affect commuters pretty quickly. So I would recommend using this model as a supportive tool rather than something that fully automates rebalancing. It works best for planning ahead and spotting likely hotspots, but staff should still monitor real-time conditions, weather, and special events.\n\n2.  **Equity considerations:** My error analysis showed that prediction accuracy wasn’t equal across all neighborhoods. Some areas, like Center City and higher-income stations had larger error, which means the model could unintentionally over or under serve certain parts of the city. If Indego relied on these predictions without oversight, it could reinforce existing inequalities in bike access by sending more rebalancing resources to already advantaged areas.\n\n3.  **Model limitations:** The model doesn’t account for special events, tourism spikes, construction, transit delays, or sudden weather changes, all of which can dramatically change bike demand. It also assumes past patterns repeat in the same way every week, which isn’t always true. If I could add more features, I would add real-time weather forecasts, event calendars, and bike lane accessibility.\n\n------------------------------------------------------------------------\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":false,"freeze":false,"echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"message":false,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":3,"embed-resources":true,"output-file":"Indego_Space_Time_Predictions_Assignment.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.24","theme":"cosmo","title":"Space-Time Prediction of Bike Share Demand: Philadelphia Indego","author":"Chloe Robinson","date":"`r Sys.Date()`","editor":"visual","toc-location":"left"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}